{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mean_squared_error(y_test, y_pred):\n",
    "#     y_test = y_test.to_numpy()\n",
    "#     # y_pred = y_pred.to_numpy()\n",
    "#     # print(y_test)\n",
    "#     # print(y_pred.shape[0])\n",
    "#     result = 0\n",
    "#     for i in range(y_pred.shape[0]):\n",
    "#         print(y_test[i])\n",
    "#         print(y_pred[i][0])\n",
    "#         print('---------')\n",
    "#         result += \n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "    \n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regressor Class\n",
    "class RegressionTree:\n",
    "    def __init__(self,n_feats = None,max_depth = 15,min_samples_split = 10):\n",
    "        self.root = None\n",
    "        self.n_feats = n_feats\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        # self.n_feats = X.shape[1] if not self.n_feats else min(self.n_feats, X.shape[1])\n",
    "        self.n_feats = X.shape[1]\n",
    "        # print('N_feats: ',self.n_feats)\n",
    "        # col_name_list = []\n",
    "        # for i in range(0, self.n_feats):\n",
    "        #     col_name_list.append(str(i))\n",
    "        # print('col_name_list: ',col_name_list)\n",
    "        self.col = list(X.columns)\n",
    "        # print('Columns: ',X.columns)\n",
    "        # X.rename(columns= col_name_list,inplace=True)\n",
    "        self.root = self.growTree(X, Y)\n",
    "\n",
    "    def growTree(self, X, Y, depth = 0):\n",
    "        df = X.copy()\n",
    "        df['y'] = Y\n",
    "        ymean = np.mean(Y)\n",
    "        self.mse = self.get_mse(Y, ymean)\n",
    "        n_sample, _ = X.shape\n",
    "        # stopping criteria\n",
    "        if (depth >= self.max_depth or n_sample <= self.min_samples_split):\n",
    "            # print('Leaf node: depth and n_sample: ',depth,' ',n_sample)\n",
    "            leaf_value = np.mean(Y)\n",
    "            return Node(value=leaf_value)\n",
    "        # print('Not leaf node: depth and n_sample: ',depth,' ',n_sample)\n",
    "        feats_idxs = list(X.columns)\n",
    "        # print('feats_idxs: ',feats_idxs)\n",
    "        best_feat, best_thresh = self.best_criteria(X, Y)\n",
    "        left_df, right_df = df[df[best_feat]<=best_thresh].copy(), df[df[best_feat]>best_thresh].copy()\n",
    "        # print('---start----')\n",
    "        # print('best_feat: ',best_feat,' best_thresh: ',best_thresh,' len(left_df): ',len(left_df),' len(right_df): ',len(right_df))\n",
    "        # print('----end-----')\n",
    "        left = self.growTree(left_df.drop('y', axis=1), left_df['y'].values.tolist(), depth+1)\n",
    "        right = self.growTree(right_df.drop('y', axis=1), right_df['y'].values.tolist(), depth+1)\n",
    "        return Node(best_feat, best_thresh, left, right)\n",
    "    \n",
    "    # find out best criteria\n",
    "    def best_criteria(self, X, Y):\n",
    "        # print(X.head())\n",
    "        df = X.copy()\n",
    "        df['y'] = Y\n",
    "        mse_base = self.mse\n",
    "        best_feature = None\n",
    "        best_thresh = None\n",
    "        # print('OK')\n",
    "        for feat in X.columns:\n",
    "            xdf = df\n",
    "            # print('xdf:\\n',xdf[feat])\n",
    "            x_mean = self.moving_average(np.unique(xdf[feat]), 2)\n",
    "            \n",
    "            for value in x_mean:\n",
    "                left_y = xdf[xdf[feat] <= value]['y'].values\n",
    "                right_y = xdf[xdf[feat] > value]['y'].values\n",
    "                left_mean = 0\n",
    "                right_mean = 0\n",
    "                if len(left_y) > 0:\n",
    "                    left_mean = np.mean(left_y)\n",
    "                if len(right_y) > 0:\n",
    "                    right_mean = np.mean(right_y)\n",
    "                \n",
    "                res_left = left_y - left_mean\n",
    "                res_right = right_y - right_mean\n",
    "\n",
    "                r = np.concatenate((res_left, res_right), axis=None)\n",
    "                n = len(r)\n",
    "                r = r ** 2\n",
    "                r = np.sum(r)\n",
    "                mse_split = r / n\n",
    "                if mse_split < mse_base:\n",
    "                    mse_base = mse_split\n",
    "                    best_feature = feat\n",
    "                    best_thresh = value\n",
    "        # print('mse_base: ',mse_base)\n",
    "        return (best_feature, best_thresh)\n",
    "    \n",
    "    def get_mse(self, y_true, y_hat):\n",
    "        n = len(y_true)\n",
    "        r = y_true - y_hat\n",
    "        r = r ** 2\n",
    "        r = np.sum(r)\n",
    "        return r / n\n",
    "    \n",
    "    def moving_average(self, x, window):\n",
    "        return np.convolve(x, np.ones(window), 'valid') / window \n",
    "    \n",
    "    def predict(self, X):\n",
    "        # print(X)\n",
    "        X = X.to_numpy().tolist()\n",
    "        return np.array([self.traverse_tree(x, self.root) for x in X])\n",
    "\n",
    "    def traverse_tree(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        fr = node.feature\n",
    "        # print('fr: ',fr)\n",
    "        index = self.col.index(fr)\n",
    "        # print('index: ',index)\n",
    "        # print('<<<<<<<<<')\n",
    "        if x[index] <= node.threshold:\n",
    "            return self.traverse_tree(x, node.left)\n",
    "        return self.traverse_tree(x, node.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, trees, n_trees, max_feature, prediction_aggrigation_calculation):\n",
    "        self.n_estimators = n_trees\n",
    "        self.max_features = max_feature\n",
    "        self.tree_feature_indexes = []\n",
    "        self.prediction_aggrigation_calculation = prediction_aggrigation_calculation \n",
    "        self.trees = trees\n",
    "\n",
    "    def _make_random_suset(self, X, y, n_subsets, replasment=True):\n",
    "        subset = []\n",
    "        # use 100% of data when replacement is true , use 50% otherwise.\n",
    "        # sử dụng 100% dữ liệu khi thay thế là đúng, sử dụng 50% nếu không.\n",
    "        sample_size = (X.shape[0] if replasment else (X.shape[0] // 2))\n",
    "        \n",
    "        X = X.to_numpy()\n",
    "        y = y.to_numpy()\n",
    "        y = np.reshape(y, (len(y),1))\n",
    "        # đổi y sang ma trận ...\n",
    "        # First concadinate the X and y datasets in order to make a choice.\n",
    "        # Đầu tiên ghép các tập dữ liệu X và y để đưa ra lựa chọn.\n",
    "        Xy = np.concatenate((X, y), axis=1)\n",
    "        # print(Xy)\n",
    "        \n",
    "        # Đổi các hàng cho nhau\n",
    "        np.random.shuffle(Xy)\n",
    "        # Select randome subset of data with replacement.\n",
    "        # Chọn tập hợp con dữ liệu ngẫu nhiên có thay thế.\n",
    "        for i in range(n_subsets):\n",
    "            index = np.random.choice(range(sample_size), size=np.shape(range(sample_size)), replace=replasment)\n",
    "            X = Xy[index][:, :-1]\n",
    "            y = Xy[index][: , -1]\n",
    "            subset.append({\"X\" : X, \"y\": y})\n",
    "        # print(subset)\n",
    "        return subset\n",
    "\n",
    "    def train(self, X, y):\n",
    "        # if the max_features is not given then select it as square root of no on feature availabe.\n",
    "        # nếu max_features không được cung cấp thì hãy chọn nó làm căn bậc hai của tính năng không có sẵn.\n",
    "        n_features = X.shape[1]\n",
    "        name_columns = list(X.columns)\n",
    "        # print('selected column names: ',name_columns)\n",
    "        if self.max_features == None:\n",
    "            self.max_features = int(math.sqrt(n_features))\n",
    "\n",
    "        # Split the dataset into number of subsets equal to n_estimators.\n",
    "        # Chia tập dữ liệu thành số tập con bằng n_estimators.\n",
    "        subsets = self._make_random_suset(X, y, self.n_estimators)\n",
    "        # print(subsets)\n",
    "\n",
    "        for i, subset in enumerate(subsets):\n",
    "            X_subset , y_subset = subset[\"X\"], subset[\"y\"]\n",
    "            # select a random sucset of features for each tree. This is called feature bagging.\n",
    "            # chọn một nhóm đặc điểm ngẫu nhiên cho mỗi cây. Điều này được gọi là đóng bao tính năng.\n",
    "            idx = np.random.choice(range(n_features), size=self.max_features, replace=False)\n",
    "            # track this for prediction.\n",
    "            # theo dõi điều này để dự đoán.\n",
    "            self.tree_feature_indexes.append(idx)\n",
    "            # Get the X with the selected features only.\n",
    "            # Chỉ nhận X với các tính năng đã chọn. X_subset= [[1,2,3], [3,4,5]]\n",
    "            X_subset = X_subset[:, idx]\n",
    "            selected_name_columns = []\n",
    "            # print(idx)\n",
    "            for j in range(len(idx)):\n",
    "                selected_name_columns.append(name_columns[idx[j]])\n",
    "            selected_name_columns.append('Y') #cột nhãn\n",
    "            # change the y_subet to i dimentional array.\n",
    "            # thay đổi mạng con thành mảng thứ i.\n",
    "            y_subset = np.expand_dims(y_subset, axis =1)\n",
    "            # print(y_subset)\n",
    "            \n",
    "            # build the model with selected features and selected random subset from dataset.\n",
    "            # xây dựng mô hình với các tính năng được chọn và tập hợp con ngẫu nhiên được chọn từ tập dữ liệu.\n",
    "            Xy_subset = np.concatenate((X_subset, y_subset), axis=1)\n",
    "            Xy_subset = pd.DataFrame(Xy_subset, columns=selected_name_columns)\n",
    "            print(Xy_subset.head())\n",
    "            X_set = Xy_subset.drop(columns=['Y'])\n",
    "            y_set = Xy_subset['Y']\n",
    "            self.trees[i].fit(X_set, y_set)\n",
    "\n",
    "    def predict(self, test_X):\n",
    "        \"\"\"\n",
    "        Predict the new samples.\n",
    "\n",
    "        :param test_X: Depentant variables for prediction.\n",
    "        Các biến phụ thuộc để dự đoán.\n",
    "        \"\"\"\n",
    "        # predict each sample one by one.\n",
    "        # dự đoán từng mẫu một.\n",
    "        y_preds = np.empty((test_X.shape[0], self.n_estimators))\n",
    "        # print(y_preds)\n",
    "        # find the prediction from each tree for eeach samples\n",
    "        # tìm dự đoán từ mỗi cây cho mỗi mẫu\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            features_index = self.tree_feature_indexes[i]\n",
    "            col_name = list(test_X.columns)\n",
    "            selected_col_name = []\n",
    "            for j in features_index:\n",
    "                selected_col_name.append(col_name[j])\n",
    "            # print(selected_col_name)\n",
    "            \n",
    "            X_selected_features = test_X[selected_col_name]\n",
    "            print(X_selected_features)\n",
    "            # print(y_preds[:, i])\n",
    "            y_preds[:, i] = tree.predict(X_selected_features)\n",
    "            # print(y_preds[:, i])\n",
    "            \n",
    "        # find the arrgrecated output.\n",
    "        # tìm đầu ra được phân bổ.\n",
    "        y_pred = self.prediction_aggrigation_calculation(y_preds)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestRegression(RandomForest):\n",
    "    \"\"\"Rnadom forest for classification task.\"\"\"\n",
    "    def __init__(self, max_feature, max_depth, n_trees=100, min_sample_split=10):\n",
    "        \"\"\"\n",
    "        :param max_depth: Int - Max depth of each tree.\n",
    "        Độ sâu tối đa của mỗi cây.\n",
    "        \n",
    "        :param n_trees: Int - Number of trees/estimetors.\n",
    "        Số cây\n",
    "        \n",
    "        :param min_sample_split: Int - minimum samples for a node to have before going for split.\n",
    "        minimum samples for a node to have before going for split.\n",
    "        các mẫu tối thiểu để một nút có trước khi chia tách.\n",
    "        \n",
    "        :param min_impurity: Int - Min inpurity a node can have.\n",
    "        \"\"\"\n",
    "        self.prediction_aggrigation_calculation = self._mean_calculation\n",
    "        \n",
    "        # Initializing the trees.\n",
    "        # Khởi tạo cây.\n",
    "        self.trees = []\n",
    "        for _ in range(n_trees):\n",
    "            self.trees.append(RegressionTree(min_samples_split=min_sample_split, max_depth=max_depth))\n",
    "\n",
    "        super().__init__(trees=self.trees, n_trees=n_trees,max_feature=max_feature,\n",
    "                         prediction_aggrigation_calculation=self.prediction_aggrigation_calculation)\n",
    "    \n",
    "    def _mean_calculation(self, y_preds):\n",
    "        \"\"\"\n",
    "        Find mean prediction of all tree prediction for each sampple.\n",
    "        Tìm dự đoán trung bình của tất cả dự đoán cây cho từng mẫu.\n",
    "\n",
    "        :param y_preds: Prediction value from number of estimators trees.\n",
    "        Giá trị dự đoán từ số lượng cây ước tính.\n",
    "        \"\"\"\n",
    "        # create a empty array to store the prediction.\n",
    "        # tạo một mảng trống để lưu dự đoán.\n",
    "        y_pred = np.empty((y_preds.shape[0], 1))\n",
    "        # print(y_pred)\n",
    "        # iterate over all the data samples.\n",
    "        # lặp qua tất cả các mẫu dữ liệu.\n",
    "        for i, sample_predictions in enumerate(y_preds):\n",
    "            # print(sample_predictions)\n",
    "            y_pred[i] = np.mean(sample_predictions)\n",
    "            # print('ok')\n",
    "            # print(y_pred)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_table('../IOT/diabetes.tab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AGE', 'SEX', 'BMI', 'BP', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6'], dtype='object')\n",
      "0      151\n",
      "1       75\n",
      "2      141\n",
      "3      206\n",
      "4      135\n",
      "      ... \n",
      "437    178\n",
      "438    104\n",
      "439    132\n",
      "440    220\n",
      "441     57\n",
      "Name: Y, Length: 442, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(columns=['Y'])\n",
    "y = data['Y']\n",
    "print(X.columns)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1) \n",
    "# print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       S5     S1  SEX      Y\n",
      "0  4.2767  190.0  1.0  146.0\n",
      "1  5.0626  186.0  2.0  185.0\n",
      "2  4.8752  225.0  2.0  102.0\n",
      "3  5.7301  199.0  1.0  258.0\n",
      "4  4.5326  205.0  1.0  183.0\n"
     ]
    }
   ],
   "source": [
    "random_forest_reg = RandomForestRegression(n_trees=1, max_feature=3, min_sample_split=10, max_depth=15)\n",
    "# Train the model.\n",
    "random_forest_reg.train(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         S5   S1  SEX\n",
      "246  5.1358  247    1\n",
      "425  4.4188  116    1\n",
      "293  4.0431  204    1\n",
      "31   4.2341  161    1\n",
      "359  4.8040  194    2\n",
      "..      ...  ...  ...\n",
      "277  4.4067  150    1\n",
      "132  4.4998  214    2\n",
      "213  4.3944  188    1\n",
      "286  4.4308  165    1\n",
      "256  4.9488  168    1\n",
      "\n",
      "[89 rows x 3 columns]\n",
      "[[125.375     ]\n",
      " [ 82.44444444]\n",
      " [ 91.1       ]\n",
      " [ 70.2       ]\n",
      " [ 79.28571429]\n",
      " [243.5       ]\n",
      " [243.5       ]\n",
      " [ 47.        ]\n",
      " [295.42857143]\n",
      " [122.5       ]\n",
      " [293.42857143]\n",
      " [158.66666667]\n",
      " [145.7       ]\n",
      " [118.        ]\n",
      " [293.42857143]\n",
      " [145.22222222]\n",
      " [243.5       ]\n",
      " [ 60.71428571]\n",
      " [ 70.2       ]\n",
      " [233.71428571]\n",
      " [ 79.28571429]\n",
      " [163.5       ]\n",
      " [153.6       ]\n",
      " [153.6       ]\n",
      " [158.5       ]\n",
      " [271.875     ]\n",
      " [ 99.25      ]\n",
      " [ 75.4       ]\n",
      " [ 60.71428571]\n",
      " [243.5       ]\n",
      " [ 79.28571429]\n",
      " [109.71428571]\n",
      " [158.66666667]\n",
      " [153.6       ]\n",
      " [271.875     ]\n",
      " [293.42857143]\n",
      " [145.22222222]\n",
      " [209.66666667]\n",
      " [132.125     ]\n",
      " [221.85714286]\n",
      " [295.42857143]\n",
      " [121.        ]\n",
      " [116.2       ]\n",
      " [ 82.44444444]\n",
      " [ 90.        ]\n",
      " [158.66666667]\n",
      " [126.66666667]\n",
      " [228.        ]\n",
      " [154.4       ]\n",
      " [216.14285714]\n",
      " [ 47.        ]\n",
      " [ 91.1       ]\n",
      " [112.5       ]\n",
      " [282.4       ]\n",
      " [293.42857143]\n",
      " [ 75.4       ]\n",
      " [132.125     ]\n",
      " [ 47.        ]\n",
      " [ 85.6       ]\n",
      " [ 68.2       ]\n",
      " [ 79.28571429]\n",
      " [125.375     ]\n",
      " [154.4       ]\n",
      " [ 75.4       ]\n",
      " [216.14285714]\n",
      " [ 91.1       ]\n",
      " [ 47.        ]\n",
      " [159.33333333]\n",
      " [293.42857143]\n",
      " [ 91.1       ]\n",
      " [152.        ]\n",
      " [ 39.        ]\n",
      " [178.        ]\n",
      " [ 82.44444444]\n",
      " [154.4       ]\n",
      " [228.        ]\n",
      " [153.6       ]\n",
      " [178.        ]\n",
      " [126.66666667]\n",
      " [ 63.33333333]\n",
      " [126.66666667]\n",
      " [145.22222222]\n",
      " [145.22222222]\n",
      " [154.4       ]\n",
      " [ 82.44444444]\n",
      " [116.2       ]\n",
      " [ 82.44444444]\n",
      " [288.        ]\n",
      " [ 78.33333333]]\n",
      "MSE:  7468.246814770229\n"
     ]
    }
   ],
   "source": [
    "# Predict the values.\n",
    "y_pred = random_forest_reg.predict(X_test)\n",
    "print(y_pred)\n",
    "#Root mean square error.\n",
    "# score = r2_score(y_test, y_pred)\n",
    "# print(\"The r2_score of the trained model\", score)\n",
    "\n",
    "\n",
    "# result = pd.DataFrame({'Actual':y_test, 'Predict':y_pred})\n",
    "\n",
    "print('MSE: ',mean_squared_error(y_test, y_pred))\n",
    "# print('r2: ', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246     78\n",
      "425    152\n",
      "293    200\n",
      "31      59\n",
      "359    311\n",
      "      ... \n",
      "277     64\n",
      "132    107\n",
      "213     49\n",
      "286     60\n",
      "256    346\n",
      "Name: Y, Length: 89, dtype: int64\n",
      "[[125.375     ]\n",
      " [ 82.44444444]\n",
      " [ 91.1       ]\n",
      " [ 70.2       ]\n",
      " [ 79.28571429]\n",
      " [243.5       ]\n",
      " [243.5       ]\n",
      " [ 47.        ]\n",
      " [295.42857143]\n",
      " [122.5       ]\n",
      " [293.42857143]\n",
      " [158.66666667]\n",
      " [145.7       ]\n",
      " [118.        ]\n",
      " [293.42857143]\n",
      " [145.22222222]\n",
      " [243.5       ]\n",
      " [ 60.71428571]\n",
      " [ 70.2       ]\n",
      " [233.71428571]\n",
      " [ 79.28571429]\n",
      " [163.5       ]\n",
      " [153.6       ]\n",
      " [153.6       ]\n",
      " [158.5       ]\n",
      " [271.875     ]\n",
      " [ 99.25      ]\n",
      " [ 75.4       ]\n",
      " [ 60.71428571]\n",
      " [243.5       ]\n",
      " [ 79.28571429]\n",
      " [109.71428571]\n",
      " [158.66666667]\n",
      " [153.6       ]\n",
      " [271.875     ]\n",
      " [293.42857143]\n",
      " [145.22222222]\n",
      " [209.66666667]\n",
      " [132.125     ]\n",
      " [221.85714286]\n",
      " [295.42857143]\n",
      " [121.        ]\n",
      " [116.2       ]\n",
      " [ 82.44444444]\n",
      " [ 90.        ]\n",
      " [158.66666667]\n",
      " [126.66666667]\n",
      " [228.        ]\n",
      " [154.4       ]\n",
      " [216.14285714]\n",
      " [ 47.        ]\n",
      " [ 91.1       ]\n",
      " [112.5       ]\n",
      " [282.4       ]\n",
      " [293.42857143]\n",
      " [ 75.4       ]\n",
      " [132.125     ]\n",
      " [ 47.        ]\n",
      " [ 85.6       ]\n",
      " [ 68.2       ]\n",
      " [ 79.28571429]\n",
      " [125.375     ]\n",
      " [154.4       ]\n",
      " [ 75.4       ]\n",
      " [216.14285714]\n",
      " [ 91.1       ]\n",
      " [ 47.        ]\n",
      " [159.33333333]\n",
      " [293.42857143]\n",
      " [ 91.1       ]\n",
      " [152.        ]\n",
      " [ 39.        ]\n",
      " [178.        ]\n",
      " [ 82.44444444]\n",
      " [154.4       ]\n",
      " [228.        ]\n",
      " [153.6       ]\n",
      " [178.        ]\n",
      " [126.66666667]\n",
      " [ 63.33333333]\n",
      " [126.66666667]\n",
      " [145.22222222]\n",
      " [145.22222222]\n",
      " [154.4       ]\n",
      " [ 82.44444444]\n",
      " [116.2       ]\n",
      " [ 82.44444444]\n",
      " [288.        ]\n",
      " [ 78.33333333]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=15, random_state=0)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = RandomForestRegressor(max_depth=15, random_state=0)\n",
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actual     Predict\n",
      "246      78  131.440000\n",
      "425     152  104.337143\n",
      "293     200  165.410000\n",
      "31       59   73.620882\n",
      "359     311  165.753333\n",
      "..      ...         ...\n",
      "277      64   93.135714\n",
      "132     107   95.575238\n",
      "213      49   86.892610\n",
      "286      60   88.229494\n",
      "256     346  166.060000\n",
      "\n",
      "[89 rows x 2 columns]\n",
      "MSE:  3827.715235726259\n",
      "r2:  0.28171579175052086\n"
     ]
    }
   ],
   "source": [
    "predicted_y = regressor.predict(X_test)\n",
    "result = pd.DataFrame({'Actual':y_test, 'Predict':predicted_y})\n",
    "print(result)\n",
    "print('MSE: ',mean_squared_error(y_test, predicted_y))\n",
    "print('r2: ', r2_score(y_test, predicted_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5175db2095d701d52086baf327a5b475e843a0ec808788361ba36bc181db60a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

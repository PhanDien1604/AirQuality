{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mean_squared_error(y_test, y_pred):\n",
    "#     y_test = y_test.to_numpy()\n",
    "#     # y_pred = y_pred.to_numpy()\n",
    "#     # print(y_test)\n",
    "#     # print(y_pred.shape[0])\n",
    "#     result = 0\n",
    "#     for i in range(y_pred.shape[0]):\n",
    "#         print(y_test[i])\n",
    "#         print(y_pred[i][0])\n",
    "#         print('---------')\n",
    "#         result += \n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "    \n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regressor Class\n",
    "class RegressionTree:\n",
    "    def __init__(self,max_depth = 15,min_samples_split = 10):\n",
    "        self.root = None\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        self.n_feats = X.shape[1]\n",
    "        self.col = list(X.columns)\n",
    "        self.root = self.growTree(X, Y)\n",
    "\n",
    "    def growTree(self, X, Y, depth = 0):\n",
    "        df = X.copy()\n",
    "        df['y'] = Y\n",
    "        ymean = np.mean(Y)\n",
    "        self.mse = self.get_mse(Y, ymean)\n",
    "        n_sample = X.shape[0]\n",
    "        # stopping criteria\n",
    "        if depth >= self.max_depth or n_sample <= self.min_samples_split:\n",
    "            leaf_value = np.mean(Y)\n",
    "            return Node(value=leaf_value)\n",
    "        best_feat, best_thresh = self.best_criteria(X, Y)\n",
    "        left_df, right_df = df[df[best_feat]<=best_thresh].copy(), df[df[best_feat]>best_thresh].copy()\n",
    "        left = self.growTree(left_df.drop('y', axis=1), left_df['y'].values.tolist(), depth+1)\n",
    "        right = self.growTree(right_df.drop('y', axis=1), right_df['y'].values.tolist(), depth+1)\n",
    "        return Node(best_feat, best_thresh, left, right)\n",
    "    \n",
    "    # find out best criteria\n",
    "    def best_criteria(self, X, Y):\n",
    "        df = X.copy()\n",
    "        df['y'] = Y\n",
    "        mse_base = self.mse\n",
    "        best_feature = best_thresh = None\n",
    "        for feat in X.columns:\n",
    "            x_mean = self.moving_average(np.unique(df[feat]), 2)\n",
    "            for value in x_mean:\n",
    "                left_y = df[df[feat] <= value]['y'].values\n",
    "                right_y = df[df[feat] > value]['y'].values\n",
    "                left_mean = right_mean = 0\n",
    "                if len(left_y) > 0:\n",
    "                    left_mean = np.mean(left_y)\n",
    "                if len(right_y) > 0:\n",
    "                    right_mean = np.mean(right_y)\n",
    "                \n",
    "                res_left, res_right = left_y - left_mean, right_y - right_mean\n",
    "                r = np.concatenate((res_left, res_right), axis=None)\n",
    "                n = len(r)\n",
    "                r = np.sum(r**2)\n",
    "                mse_split = r / n\n",
    "                if mse_split < mse_base:\n",
    "                    mse_base = mse_split\n",
    "                    best_feature = feat\n",
    "                    best_thresh = value\n",
    "        return (best_feature, best_thresh)\n",
    "    \n",
    "    def get_mse(self, y_true, y_hat):\n",
    "        n = len(y_true)\n",
    "        r = np.sum((y_true - y_hat)**2)\n",
    "        return r / n\n",
    "    \n",
    "    def moving_average(self, x, window):\n",
    "        return np.convolve(x, np.ones(window), 'valid') / window \n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = X.to_numpy().tolist()\n",
    "        return np.array([self.traverse_tree(x, self.root) for x in X])\n",
    "\n",
    "    def traverse_tree(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        fr = node.feature\n",
    "        index = self.col.index(fr)\n",
    "        if x[index] <= node.threshold:\n",
    "            return self.traverse_tree(x, node.left)\n",
    "        return self.traverse_tree(x, node.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, trees, n_trees, max_feature, prediction_aggrigation_calculation):\n",
    "        self.n_estimators = n_trees\n",
    "        self.max_features = max_feature\n",
    "        self.tree_feature_indexes = []\n",
    "        self.prediction_aggrigation_calculation = prediction_aggrigation_calculation \n",
    "        self.trees = trees\n",
    "\n",
    "    def _make_random_suset(self, X, y, n_subsets, replasment=True):\n",
    "        subset = []\n",
    "        # use 100% of data when replacement is true , use 50% otherwise.\n",
    "        # sử dụng 100% dữ liệu khi thay thế là đúng, sử dụng 50% nếu không.\n",
    "        sample_size = (X.shape[0] if replasment else (X.shape[0] // 2))\n",
    "        \n",
    "        X = X.to_numpy()\n",
    "        y = y.to_numpy()\n",
    "        y = np.reshape(y, (len(y),1))\n",
    "        # đổi y sang ma trận ...\n",
    "        # First concadinate the X and y datasets in order to make a choice.\n",
    "        # Đầu tiên ghép các tập dữ liệu X và y để đưa ra lựa chọn.\n",
    "        Xy = np.concatenate((X, y), axis=1)\n",
    "        # print(Xy)\n",
    "        \n",
    "        # Đổi các hàng cho nhau\n",
    "        np.random.shuffle(Xy)\n",
    "        # Select randome subset of data with replacement.\n",
    "        # Chọn tập hợp con dữ liệu ngẫu nhiên có thay thế.\n",
    "        for i in range(n_subsets):\n",
    "            index = np.random.choice(range(sample_size), size=np.shape(range(sample_size)), replace=replasment)\n",
    "            X = Xy[index][:, :-1]\n",
    "            y = Xy[index][: , -1]\n",
    "            subset.append({\"X\" : X, \"y\": y})\n",
    "        # print(subset)\n",
    "        return subset\n",
    "\n",
    "    def train(self, X, y):\n",
    "        # if the max_features is not given then select it as square root of no on feature availabe.\n",
    "        # nếu max_features không được cung cấp thì hãy chọn nó làm căn bậc hai của tính năng không có sẵn.\n",
    "        n_features = X.shape[1]\n",
    "        name_columns = list(X.columns)\n",
    "        # print('selected column names: ',name_columns)\n",
    "        if self.max_features == None:\n",
    "            self.max_features = int(math.sqrt(n_features))\n",
    "\n",
    "        # Split the dataset into number of subsets equal to n_estimators.\n",
    "        # Chia tập dữ liệu thành số tập con bằng n_estimators.\n",
    "        subsets = self._make_random_suset(X, y, self.n_estimators)\n",
    "        # print(subsets)\n",
    "\n",
    "        for i, subset in enumerate(subsets):\n",
    "            X_subset , y_subset = subset[\"X\"], subset[\"y\"]\n",
    "            # select a random sucset of features for each tree. This is called feature bagging.\n",
    "            # chọn một nhóm đặc điểm ngẫu nhiên cho mỗi cây. Điều này được gọi là đóng bao tính năng.\n",
    "            idx = np.random.choice(range(n_features), size=self.max_features, replace=False)\n",
    "            # track this for prediction.\n",
    "            # theo dõi điều này để dự đoán.\n",
    "            self.tree_feature_indexes.append(idx)\n",
    "            # Get the X with the selected features only.\n",
    "            # Chỉ nhận X với các tính năng đã chọn. X_subset= [[1,2,3], [3,4,5]]\n",
    "            X_subset = X_subset[:, idx]\n",
    "            selected_name_columns = []\n",
    "            # print(idx)\n",
    "            for j in range(len(idx)):\n",
    "                selected_name_columns.append(name_columns[idx[j]])\n",
    "            selected_name_columns.append('Y') #cột nhãn\n",
    "            # change the y_subet to i dimentional array.\n",
    "            # thay đổi mạng con thành mảng thứ i.\n",
    "            y_subset = np.expand_dims(y_subset, axis =1)\n",
    "            # print(y_subset)\n",
    "            \n",
    "            # build the model with selected features and selected random subset from dataset.\n",
    "            # xây dựng mô hình với các tính năng được chọn và tập hợp con ngẫu nhiên được chọn từ tập dữ liệu.\n",
    "            Xy_subset = np.concatenate((X_subset, y_subset), axis=1)\n",
    "            Xy_subset = pd.DataFrame(Xy_subset, columns=selected_name_columns)\n",
    "            print(Xy_subset.head())\n",
    "            X_set = Xy_subset.drop(columns=['Y'])\n",
    "            y_set = Xy_subset['Y']\n",
    "            self.trees[i].fit(X_set, y_set)\n",
    "\n",
    "    def predict(self, test_X):\n",
    "        \"\"\"\n",
    "        Predict the new samples.\n",
    "\n",
    "        :param test_X: Depentant variables for prediction.\n",
    "        Các biến phụ thuộc để dự đoán.\n",
    "        \"\"\"\n",
    "        # predict each sample one by one.\n",
    "        # dự đoán từng mẫu một.\n",
    "        y_preds = np.empty((test_X.shape[0], self.n_estimators))\n",
    "        # print(y_preds)\n",
    "        # find the prediction from each tree for eeach samples\n",
    "        # tìm dự đoán từ mỗi cây cho mỗi mẫu\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            features_index = self.tree_feature_indexes[i]\n",
    "            col_name = list(test_X.columns)\n",
    "            selected_col_name = []\n",
    "            for j in features_index:\n",
    "                selected_col_name.append(col_name[j])\n",
    "            # print(selected_col_name)\n",
    "            \n",
    "            X_selected_features = test_X[selected_col_name]\n",
    "            print(X_selected_features)\n",
    "            # print(y_preds[:, i])\n",
    "            y_preds[:, i] = tree.predict(X_selected_features)\n",
    "            # print(y_preds[:, i])\n",
    "            \n",
    "        # find the arrgrecated output.\n",
    "        # tìm đầu ra được phân bổ.\n",
    "        y_pred = self.prediction_aggrigation_calculation(y_preds)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestRegression(RandomForest):\n",
    "    \"\"\"Rnadom forest for classification task.\"\"\"\n",
    "    def __init__(self, max_feature, max_depth, n_trees=100, min_sample_split=10):\n",
    "        \"\"\"\n",
    "        :param max_depth: Int - Max depth of each tree.\n",
    "        Độ sâu tối đa của mỗi cây.\n",
    "        \n",
    "        :param n_trees: Int - Number of trees/estimetors.\n",
    "        Số cây\n",
    "        \n",
    "        :param min_sample_split: Int - minimum samples for a node to have before going for split.\n",
    "        minimum samples for a node to have before going for split.\n",
    "        các mẫu tối thiểu để một nút có trước khi chia tách.\n",
    "        \n",
    "        :param min_impurity: Int - Min inpurity a node can have.\n",
    "        \"\"\"\n",
    "        self.prediction_aggrigation_calculation = self._mean_calculation\n",
    "        \n",
    "        # Initializing the trees.\n",
    "        # Khởi tạo cây.\n",
    "        self.trees = []\n",
    "        for _ in range(n_trees):\n",
    "            self.trees.append(RegressionTree(min_samples_split=min_sample_split, max_depth=max_depth))\n",
    "\n",
    "        super().__init__(trees=self.trees, n_trees=n_trees,max_feature=max_feature,\n",
    "                         prediction_aggrigation_calculation=self.prediction_aggrigation_calculation)\n",
    "    \n",
    "    def _mean_calculation(self, y_preds):\n",
    "        \"\"\"\n",
    "        Find mean prediction of all tree prediction for each sampple.\n",
    "        Tìm dự đoán trung bình của tất cả dự đoán cây cho từng mẫu.\n",
    "\n",
    "        :param y_preds: Prediction value from number of estimators trees.\n",
    "        Giá trị dự đoán từ số lượng cây ước tính.\n",
    "        \"\"\"\n",
    "        # create a empty array to store the prediction.\n",
    "        # tạo một mảng trống để lưu dự đoán.\n",
    "        y_pred = np.empty((y_preds.shape[0], 1))\n",
    "        # print(y_pred)\n",
    "        # iterate over all the data samples.\n",
    "        # lặp qua tất cả các mẫu dữ liệu.\n",
    "        for i, sample_predictions in enumerate(y_preds):\n",
    "            # print(sample_predictions)\n",
    "            y_pred[i] = np.mean(sample_predictions)\n",
    "            # print('ok')\n",
    "            # print(y_pred)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_table('D:\\\\Backup Data from Drive C\\\\Desktop\\\\Nhập môn KHDL\\\\Machine Learning\\\\IOT\\\\diabetes.tab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AGE', 'SEX', 'BMI', 'BP', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6'], dtype='object')\n",
      "0      151\n",
      "1       75\n",
      "2      141\n",
      "3      206\n",
      "4      135\n",
      "      ... \n",
      "437    178\n",
      "438    104\n",
      "439    132\n",
      "440    220\n",
      "441     57\n",
      "Name: Y, Length: 442, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(columns=['Y'])\n",
    "y = data['Y']\n",
    "print(X.columns)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1) \n",
    "# print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SEX    S6      S5      Y\n",
      "0  1.0  94.0  4.7449  154.0\n",
      "1  2.0  99.0  4.9628  164.0\n",
      "2  1.0  60.0  3.8918   65.0\n",
      "3  1.0  73.0  4.2905  118.0\n",
      "4  2.0  78.0  4.2047   77.0\n",
      "      S6   AGE  SEX      Y\n",
      "0   90.0  34.0  2.0  181.0\n",
      "1  108.0  34.0  2.0   42.0\n",
      "2   80.0  51.0  2.0   91.0\n",
      "3   88.0  37.0  2.0  142.0\n",
      "4   82.0  67.0  1.0   90.0\n",
      "      S2   BMI  SEX      Y\n",
      "0  103.2  21.6  1.0   75.0\n",
      "1   83.8  20.9  1.0   86.0\n",
      "2  122.4  26.6  2.0  245.0\n",
      "3   91.8  18.9  1.0   72.0\n",
      "4  101.6  26.5  1.0  258.0\n",
      "      S6      BP   AGE      Y\n",
      "0   93.0   84.00  37.0  128.0\n",
      "1   94.0   94.67  35.0   58.0\n",
      "2   92.0   87.00  67.0  127.0\n",
      "3  100.0  110.00  48.0   65.0\n",
      "4   99.0   97.00  53.0   49.0\n",
      "      S1      BP      S5      Y\n",
      "0  218.0   91.33  4.9053  259.0\n",
      "1  156.0   82.00  3.9890  134.0\n",
      "2  253.0  123.00  5.4250  252.0\n",
      "3  194.0  108.00  5.3471  246.0\n",
      "4  161.0  101.00  4.2047   44.0\n",
      "      S1   AGE     S6      Y\n",
      "0  162.0  25.0   87.0   49.0\n",
      "1  182.0  32.0   89.0  129.0\n",
      "2  180.0  29.0   88.0  310.0\n",
      "3  261.0  51.0   93.0   84.0\n",
      "4  206.0  33.0  105.0  179.0\n",
      "     S4     S1   AGE      Y\n",
      "0  3.00  141.0  24.0  185.0\n",
      "1  3.00  189.0  36.0  111.0\n",
      "2  3.00  202.0  61.0  118.0\n",
      "3  4.42  146.0  67.0  124.0\n",
      "4  3.00  143.0  67.0   71.0\n",
      "       BP     S1  SEX      Y\n",
      "0   88.00  143.0  2.0   43.0\n",
      "1  123.33  187.0  1.0  257.0\n",
      "2   87.00  181.0  2.0   42.0\n",
      "3   81.00  152.0  2.0   77.0\n",
      "4   96.00  207.0  2.0  172.0\n",
      "     S3    S4   AGE      Y\n",
      "0  43.0  4.63  55.0  258.0\n",
      "1  41.0  4.00  72.0  141.0\n",
      "2  58.0  3.00  41.0  125.0\n",
      "3  30.0  6.00  37.0  142.0\n",
      "4  42.0  4.64  56.0  140.0\n",
      "      S2    S3   AGE      Y\n",
      "0  100.0  47.0  59.0  160.0\n",
      "1  107.6  40.0  57.0  310.0\n",
      "2   84.2  56.0  32.0  187.0\n",
      "3  136.0  49.0  52.0  242.0\n",
      "4  111.2  67.0  50.0   96.0\n"
     ]
    }
   ],
   "source": [
    "random_forest_reg = RandomForestRegression(n_trees=10, max_feature=3, min_sample_split=10, max_depth=15)\n",
    "# Train the model.\n",
    "random_forest_reg.train(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SEX   S6      S5\n",
      "246    1   77  5.1358\n",
      "425    1   79  4.4188\n",
      "293    1   91  4.0431\n",
      "31     1   81  4.2341\n",
      "359    2  106  4.8040\n",
      "..   ...  ...     ...\n",
      "277    1   95  4.4067\n",
      "132    2   97  4.4998\n",
      "213    1   93  4.3944\n",
      "286    1   90  4.4308\n",
      "256    1   94  4.9488\n",
      "\n",
      "[89 rows x 3 columns]\n",
      "      S6  AGE  SEX\n",
      "246   77   60    1\n",
      "425   79   27    1\n",
      "293   91   29    1\n",
      "31    81   42    1\n",
      "359  106   59    2\n",
      "..   ...  ...  ...\n",
      "277   95   39    1\n",
      "132   97   53    2\n",
      "213   93   49    1\n",
      "286   90   38    1\n",
      "256   94   35    1\n",
      "\n",
      "[89 rows x 3 columns]\n",
      "        S2   BMI  SEX\n",
      "246  148.0  23.4    1\n",
      "425   43.4  22.6    1\n",
      "293  142.6  35.0    1\n",
      "31    81.2  20.3    1\n",
      "359  126.6  26.9    2\n",
      "..     ...   ...  ...\n",
      "277   65.6  20.9    1\n",
      "132  146.0  24.4    2\n",
      "213  114.8  19.8    1\n",
      "286   60.2  21.3    1\n",
      "256  102.8  41.3    1\n",
      "\n",
      "[89 rows x 3 columns]\n",
      "      S6      BP  AGE\n",
      "246   77   76.67   60\n",
      "425   79   71.00   27\n",
      "293   91   98.33   29\n",
      "31    81   71.00   42\n",
      "359  106  104.00   59\n",
      "..   ...     ...  ...\n",
      "277   95   95.00   39\n",
      "132   97   92.00   53\n",
      "213   93   88.00   49\n",
      "286   90   72.00   38\n",
      "256   94   81.00   35\n",
      "\n",
      "[89 rows x 3 columns]\n",
      "      S1      BP      S5\n",
      "246  247   76.67  5.1358\n",
      "425  116   71.00  4.4188\n",
      "293  204   98.33  4.0431\n",
      "31   161   71.00  4.2341\n",
      "359  194  104.00  4.8040\n",
      "..   ...     ...     ...\n",
      "277  150   95.00  4.4067\n",
      "132  214   92.00  4.4998\n",
      "213  188   88.00  4.3944\n",
      "286  165   72.00  4.4308\n",
      "256  168   81.00  4.9488\n",
      "\n",
      "[89 rows x 3 columns]\n",
      "      S1  AGE   S6\n",
      "246  247   60   77\n",
      "425  116   27   79\n",
      "293  204   29   91\n",
      "31   161   42   81\n",
      "359  194   59  106\n",
      "..   ...  ...  ...\n",
      "277  150   39   95\n",
      "132  214   53   97\n",
      "213  188   49   93\n",
      "286  165   38   90\n",
      "256  168   35   94\n",
      "\n",
      "[89 rows x 3 columns]\n",
      "       S4   S1  AGE\n",
      "246  3.80  247   60\n",
      "425  2.00  116   27\n",
      "293  4.08  204   29\n",
      "31   2.00  161   42\n",
      "359  5.00  194   59\n",
      "..    ...  ...  ...\n",
      "277  2.00  150   39\n",
      "132  4.00  214   53\n",
      "213  3.00  188   49\n",
      "286  2.00  165   38\n",
      "256  5.00  168   35\n",
      "\n",
      "[89 rows x 3 columns]\n",
      "         BP   S1  SEX\n",
      "246   76.67  247    1\n",
      "425   71.00  116    1\n",
      "293   98.33  204    1\n",
      "31    71.00  161    1\n",
      "359  104.00  194    2\n",
      "..      ...  ...  ...\n",
      "277   95.00  150    1\n",
      "132   92.00  214    2\n",
      "213   88.00  188    1\n",
      "286   72.00  165    1\n",
      "256   81.00  168    1\n",
      "\n",
      "[89 rows x 3 columns]\n",
      "       S3    S4  AGE\n",
      "246  65.0  3.80   60\n",
      "425  56.0  2.00   27\n",
      "293  50.0  4.08   29\n",
      "31   66.0  2.00   42\n",
      "359  43.0  5.00   59\n",
      "..    ...   ...  ...\n",
      "277  68.0  2.00   39\n",
      "132  50.0  4.00   53\n",
      "213  57.0  3.00   49\n",
      "286  88.0  2.00   38\n",
      "256  37.0  5.00   35\n",
      "\n",
      "[89 rows x 3 columns]\n",
      "        S2    S3  AGE\n",
      "246  148.0  65.0   60\n",
      "425   43.4  56.0   27\n",
      "293  142.6  50.0   29\n",
      "31    81.2  66.0   42\n",
      "359  126.6  43.0   59\n",
      "..     ...   ...  ...\n",
      "277   65.6  68.0   39\n",
      "132  146.0  50.0   53\n",
      "213  114.8  57.0   49\n",
      "286   60.2  88.0   38\n",
      "256  102.8  37.0   35\n",
      "\n",
      "[89 rows x 3 columns]\n",
      "[[138.60208333]\n",
      " [114.31333333]\n",
      " [120.62896825]\n",
      " [ 86.99777778]\n",
      " [195.16277778]\n",
      " [167.6631746 ]\n",
      " [195.29444444]\n",
      " [160.55166667]\n",
      " [191.22670635]\n",
      " [118.02690476]\n",
      " [177.88277778]\n",
      " [138.14638889]\n",
      " [111.12583333]\n",
      " [102.92968254]\n",
      " [174.24111111]\n",
      " [145.58027778]\n",
      " [175.18055556]\n",
      " [ 89.06468254]\n",
      " [156.385     ]\n",
      " [162.00666667]\n",
      " [179.36892857]\n",
      " [100.87690476]\n",
      " [124.43607143]\n",
      " [126.2727381 ]\n",
      " [121.48420635]\n",
      " [198.99555556]\n",
      " [135.10079365]\n",
      " [154.555     ]\n",
      " [166.91833333]\n",
      " [167.90678571]\n",
      " [153.08559524]\n",
      " [164.69934524]\n",
      " [143.75230159]\n",
      " [104.92337302]\n",
      " [162.19134921]\n",
      " [197.26305556]\n",
      " [ 95.28388889]\n",
      " [190.41194444]\n",
      " [154.37055556]\n",
      " [150.29440476]\n",
      " [161.46170635]\n",
      " [167.23083333]\n",
      " [105.13194444]\n",
      " [123.73083333]\n",
      " [153.41777778]\n",
      " [235.27492063]\n",
      " [123.43055556]\n",
      " [133.40214286]\n",
      " [151.4625    ]\n",
      " [156.77083333]\n",
      " [102.71722222]\n",
      " [159.95305556]\n",
      " [129.39186508]\n",
      " [151.135     ]\n",
      " [173.46583333]\n",
      " [136.68571429]\n",
      " [184.59833333]\n",
      " [130.005     ]\n",
      " [116.66916667]\n",
      " [104.47083333]\n",
      " [153.26619048]\n",
      " [144.18428571]\n",
      " [183.74416667]\n",
      " [115.45805556]\n",
      " [206.23      ]\n",
      " [ 73.90611111]\n",
      " [ 92.67361111]\n",
      " [129.5647619 ]\n",
      " [176.10535714]\n",
      " [ 82.45666667]\n",
      " [156.3815873 ]\n",
      " [ 99.41583333]\n",
      " [ 94.55333333]\n",
      " [132.61472222]\n",
      " [178.19444444]\n",
      " [130.84555556]\n",
      " [165.33361111]\n",
      " [ 95.69297619]\n",
      " [222.74785714]\n",
      " [146.56194444]\n",
      " [132.36      ]\n",
      " [143.7347619 ]\n",
      " [ 96.79777778]\n",
      " [158.80670635]\n",
      " [ 72.71642857]\n",
      " [178.88210317]\n",
      " [150.07138889]\n",
      " [157.92722222]\n",
      " [133.79285714]]\n",
      "MSE:  3981.99437790164\n"
     ]
    }
   ],
   "source": [
    "# Predict the values.\n",
    "y_pred = random_forest_reg.predict(X_test)\n",
    "print(y_pred)\n",
    "#Root mean square error.\n",
    "# score = r2_score(y_test, y_pred)\n",
    "# print(\"The r2_score of the trained model\", score)\n",
    "\n",
    "\n",
    "# result = pd.DataFrame({'Actual':y_test, 'Predict':y_pred})\n",
    "\n",
    "print('MSE: ',mean_squared_error(y_test, y_pred))\n",
    "# print('r2: ', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246     78\n",
      "425    152\n",
      "293    200\n",
      "31      59\n",
      "359    311\n",
      "      ... \n",
      "277     64\n",
      "132    107\n",
      "213     49\n",
      "286     60\n",
      "256    346\n",
      "Name: Y, Length: 89, dtype: int64\n",
      "[[138.60208333]\n",
      " [114.31333333]\n",
      " [120.62896825]\n",
      " [ 86.99777778]\n",
      " [195.16277778]\n",
      " [167.6631746 ]\n",
      " [195.29444444]\n",
      " [160.55166667]\n",
      " [191.22670635]\n",
      " [118.02690476]\n",
      " [177.88277778]\n",
      " [138.14638889]\n",
      " [111.12583333]\n",
      " [102.92968254]\n",
      " [174.24111111]\n",
      " [145.58027778]\n",
      " [175.18055556]\n",
      " [ 89.06468254]\n",
      " [156.385     ]\n",
      " [162.00666667]\n",
      " [179.36892857]\n",
      " [100.87690476]\n",
      " [124.43607143]\n",
      " [126.2727381 ]\n",
      " [121.48420635]\n",
      " [198.99555556]\n",
      " [135.10079365]\n",
      " [154.555     ]\n",
      " [166.91833333]\n",
      " [167.90678571]\n",
      " [153.08559524]\n",
      " [164.69934524]\n",
      " [143.75230159]\n",
      " [104.92337302]\n",
      " [162.19134921]\n",
      " [197.26305556]\n",
      " [ 95.28388889]\n",
      " [190.41194444]\n",
      " [154.37055556]\n",
      " [150.29440476]\n",
      " [161.46170635]\n",
      " [167.23083333]\n",
      " [105.13194444]\n",
      " [123.73083333]\n",
      " [153.41777778]\n",
      " [235.27492063]\n",
      " [123.43055556]\n",
      " [133.40214286]\n",
      " [151.4625    ]\n",
      " [156.77083333]\n",
      " [102.71722222]\n",
      " [159.95305556]\n",
      " [129.39186508]\n",
      " [151.135     ]\n",
      " [173.46583333]\n",
      " [136.68571429]\n",
      " [184.59833333]\n",
      " [130.005     ]\n",
      " [116.66916667]\n",
      " [104.47083333]\n",
      " [153.26619048]\n",
      " [144.18428571]\n",
      " [183.74416667]\n",
      " [115.45805556]\n",
      " [206.23      ]\n",
      " [ 73.90611111]\n",
      " [ 92.67361111]\n",
      " [129.5647619 ]\n",
      " [176.10535714]\n",
      " [ 82.45666667]\n",
      " [156.3815873 ]\n",
      " [ 99.41583333]\n",
      " [ 94.55333333]\n",
      " [132.61472222]\n",
      " [178.19444444]\n",
      " [130.84555556]\n",
      " [165.33361111]\n",
      " [ 95.69297619]\n",
      " [222.74785714]\n",
      " [146.56194444]\n",
      " [132.36      ]\n",
      " [143.7347619 ]\n",
      " [ 96.79777778]\n",
      " [158.80670635]\n",
      " [ 72.71642857]\n",
      " [178.88210317]\n",
      " [150.07138889]\n",
      " [157.92722222]\n",
      " [133.79285714]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=15, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=15, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=15, random_state=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = RandomForestRegressor(max_depth=15, random_state=0)\n",
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actual     Predict\n",
      "246      78  131.440000\n",
      "425     152  104.337143\n",
      "293     200  165.410000\n",
      "31       59   73.620882\n",
      "359     311  165.753333\n",
      "..      ...         ...\n",
      "277      64   93.135714\n",
      "132     107   95.575238\n",
      "213      49   86.892610\n",
      "286      60   88.229494\n",
      "256     346  166.060000\n",
      "\n",
      "[89 rows x 2 columns]\n",
      "MSE:  3827.715235726259\n",
      "r2:  0.28171579175052086\n"
     ]
    }
   ],
   "source": [
    "predicted_y = regressor.predict(X_test)\n",
    "result = pd.DataFrame({'Actual':y_test, 'Predict':predicted_y})\n",
    "print(result)\n",
    "print('MSE: ',mean_squared_error(y_test, predicted_y))\n",
    "print('r2: ', r2_score(y_test, predicted_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25034407fed5d681614dac11a1c0537e8cb49e3a8883c071303eea01322943d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

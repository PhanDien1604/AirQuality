{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_test, y_pred):\n",
    "    y_test = y_test.to_numpy()\n",
    "    # y_pred = y_pred.to_numpy()\n",
    "    # print(y_test)\n",
    "    # print(y_pred.shape[0])\n",
    "    result = 0\n",
    "    n = y_pred.shape[0]\n",
    "    for i in range(n):\n",
    "        result += math.pow((y_test[i] - y_pred[i][0]), 2)\n",
    "    result /= n\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score(y_test, y_pred):\n",
    "    y_test = y_test.to_numpy()\n",
    "    y_test_avg = np.mean(y_test)\n",
    "    result = 0\n",
    "    n = y_pred.shape[0]\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for i in range(n):\n",
    "        numerator += math.pow((y_test[i] - y_pred[i][0]), 2)\n",
    "        denominator += math.pow((y_test[i] - y_test_avg), 2)\n",
    "    result = 1 - (numerator / denominator)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "    \n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regressor Class\n",
    "class RegressionTree:\n",
    "    def __init__(self,max_depth = 15,min_samples_split = 10):\n",
    "        self.root = None\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        self.n_feats = X.shape[1]\n",
    "        self.col = list(X.columns)\n",
    "        self.root = self.growTree(X, Y)\n",
    "\n",
    "    def growTree(self, X, Y, depth = 0):\n",
    "        df = X.copy()\n",
    "        df['y'] = Y\n",
    "        ymean = np.mean(Y)\n",
    "        self.mse = self.get_mse(Y, ymean)\n",
    "        n_sample = X.shape[0]\n",
    "        # stopping criteria\n",
    "        if depth >= self.max_depth or n_sample <= self.min_samples_split:\n",
    "            leaf_value = np.mean(Y)\n",
    "            return Node(value=leaf_value)\n",
    "        best_feat, best_thresh = self.best_criteria(X, Y)\n",
    "        left_df, right_df = df[df[best_feat]<=best_thresh].copy(), df[df[best_feat]>best_thresh].copy()\n",
    "        left = self.growTree(left_df.drop('y', axis=1), left_df['y'].values.tolist(), depth+1)\n",
    "        right = self.growTree(right_df.drop('y', axis=1), right_df['y'].values.tolist(), depth+1)\n",
    "        return Node(best_feat, best_thresh, left, right)\n",
    "    \n",
    "    # find out best criteria\n",
    "    def best_criteria(self, X, Y):\n",
    "        df = X.copy()\n",
    "        df['y'] = Y\n",
    "        mse_base = self.mse\n",
    "        best_feature = best_thresh = None\n",
    "        for feat in X.columns:\n",
    "            x_mean = self.moving_average(np.unique(df[feat]), 2)\n",
    "            for value in x_mean:\n",
    "                left_y = df[df[feat] <= value]['y'].values\n",
    "                right_y = df[df[feat] > value]['y'].values\n",
    "                left_mean = right_mean = 0\n",
    "                if len(left_y) > 0:\n",
    "                    left_mean = np.mean(left_y)\n",
    "                if len(right_y) > 0:\n",
    "                    right_mean = np.mean(right_y)\n",
    "                \n",
    "                res_left, res_right = left_y - left_mean, right_y - right_mean\n",
    "                r = np.concatenate((res_left, res_right), axis=None)\n",
    "                n = len(r)\n",
    "                r = np.sum(r**2)\n",
    "                mse_split = r / n\n",
    "                if mse_split < mse_base:\n",
    "                    mse_base = mse_split\n",
    "                    best_feature = feat\n",
    "                    best_thresh = value\n",
    "        return (best_feature, best_thresh)\n",
    "    \n",
    "    def get_mse(self, y_true, y_hat):\n",
    "        n = len(y_true)\n",
    "        r = np.sum((y_true - y_hat)**2)\n",
    "        return r / n\n",
    "    \n",
    "    def moving_average(self, x, window):\n",
    "        return np.convolve(x, np.ones(window), 'valid') / window \n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = X.to_numpy().tolist()\n",
    "        return np.array([self.traverse_tree(x, self.root) for x in X])\n",
    "\n",
    "    def traverse_tree(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        fr = node.feature\n",
    "        index = self.col.index(fr)\n",
    "        if x[index] <= node.threshold:\n",
    "            return self.traverse_tree(x, node.left)\n",
    "        return self.traverse_tree(x, node.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, trees, n_trees, max_feature, prediction_aggrigation_calculation):\n",
    "        self.n_estimators = n_trees\n",
    "        self.max_features = max_feature\n",
    "        self.tree_feature_indexes = []\n",
    "        self.prediction_aggrigation_calculation = prediction_aggrigation_calculation \n",
    "        self.trees = trees\n",
    "\n",
    "    def _make_random_suset(self, X, y, n_subsets, replasment=True):\n",
    "        subset = []\n",
    "        # use 100% of data when replacement is true , use 50% otherwise.\n",
    "        # sử dụng 100% dữ liệu khi thay thế là đúng, sử dụng 50% nếu không.\n",
    "        sample_size = (X.shape[0] if replasment else (X.shape[0] // 2))\n",
    "        \n",
    "        X = X.to_numpy()\n",
    "        y = y.to_numpy()\n",
    "        y = np.reshape(y, (len(y),1))\n",
    "        # đổi y sang ma trận ...\n",
    "        # First concadinate the X and y datasets in order to make a choice.\n",
    "        # Đầu tiên ghép các tập dữ liệu X và y để đưa ra lựa chọn.\n",
    "        Xy = np.concatenate((X, y), axis=1)\n",
    "        # print(Xy)\n",
    "        \n",
    "        # Đổi các hàng cho nhau\n",
    "        np.random.shuffle(Xy)\n",
    "        # Select randome subset of data with replacement.\n",
    "        # Chọn tập hợp con dữ liệu ngẫu nhiên có thay thế.\n",
    "        for i in range(n_subsets):\n",
    "            index = np.random.choice(range(sample_size), size=np.shape(range(sample_size)), replace=replasment)\n",
    "            X = Xy[index][:, :-1]\n",
    "            y = Xy[index][: , -1]\n",
    "            subset.append({\"X\" : X, \"y\": y})\n",
    "        # print(subset)\n",
    "        return subset\n",
    "\n",
    "    def train(self, X, y):\n",
    "        # if the max_features is not given then select it as square root of no on feature availabe.\n",
    "        # nếu max_features không được cung cấp thì hãy chọn nó làm căn bậc hai của tính năng không có sẵn.\n",
    "        n_features = X.shape[1]\n",
    "        name_columns = list(X.columns)\n",
    "        # print('selected column names: ',name_columns)\n",
    "        if self.max_features == None:\n",
    "            self.max_features = int(math.sqrt(n_features))\n",
    "\n",
    "        # Split the dataset into number of subsets equal to n_estimators.\n",
    "        # Chia tập dữ liệu thành số tập con bằng n_estimators.\n",
    "        subsets = self._make_random_suset(X, y, self.n_estimators)\n",
    "        # print(subsets)\n",
    "\n",
    "        for i, subset in enumerate(subsets):\n",
    "            X_subset , y_subset = subset[\"X\"], subset[\"y\"]\n",
    "            # select a random sucset of features for each tree. This is called feature bagging.\n",
    "            # chọn một nhóm đặc điểm ngẫu nhiên cho mỗi cây. Điều này được gọi là đóng bao tính năng.\n",
    "            idx = np.random.choice(range(n_features), size=self.max_features, replace=False)\n",
    "            # track this for prediction.\n",
    "            # theo dõi điều này để dự đoán.\n",
    "            self.tree_feature_indexes.append(idx)\n",
    "            # Get the X with the selected features only.\n",
    "            # Chỉ nhận X với các tính năng đã chọn. X_subset= [[1,2,3], [3,4,5]]\n",
    "            X_subset = X_subset[:, idx]\n",
    "            selected_name_columns = []\n",
    "            # print(idx)\n",
    "            for j in range(len(idx)):\n",
    "                selected_name_columns.append(name_columns[idx[j]])\n",
    "            selected_name_columns.append('Y') #cột nhãn\n",
    "            # change the y_subet to i dimentional array.\n",
    "            # thay đổi mạng con thành mảng thứ i.\n",
    "            y_subset = np.expand_dims(y_subset, axis =1)\n",
    "            # print(y_subset)\n",
    "            \n",
    "            # build the model with selected features and selected random subset from dataset.\n",
    "            # xây dựng mô hình với các tính năng được chọn và tập hợp con ngẫu nhiên được chọn từ tập dữ liệu.\n",
    "            Xy_subset = np.concatenate((X_subset, y_subset), axis=1)\n",
    "            Xy_subset = pd.DataFrame(Xy_subset, columns=selected_name_columns)\n",
    "            print(Xy_subset.head())\n",
    "            X_set = Xy_subset.drop(columns=['Y'])\n",
    "            y_set = Xy_subset['Y']\n",
    "            self.trees[i].fit(X_set, y_set)\n",
    "\n",
    "    def predict(self, test_X):\n",
    "        \"\"\"\n",
    "        Predict the new samples.\n",
    "\n",
    "        :param test_X: Depentant variables for prediction.\n",
    "        Các biến phụ thuộc để dự đoán.\n",
    "        \"\"\"\n",
    "        # predict each sample one by one.\n",
    "        # dự đoán từng mẫu một.\n",
    "        y_preds = np.empty((test_X.shape[0], self.n_estimators))\n",
    "        # print(y_preds)\n",
    "        # find the prediction from each tree for eeach samples\n",
    "        # tìm dự đoán từ mỗi cây cho mỗi mẫu\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            features_index = self.tree_feature_indexes[i]\n",
    "            col_name = list(test_X.columns)\n",
    "            selected_col_name = []\n",
    "            for j in features_index:\n",
    "                selected_col_name.append(col_name[j])\n",
    "            # print(selected_col_name)\n",
    "            \n",
    "            X_selected_features = test_X[selected_col_name]\n",
    "            print(X_selected_features)\n",
    "            # print(y_preds[:, i])\n",
    "            y_preds[:, i] = tree.predict(X_selected_features)\n",
    "            # print(y_preds[:, i])\n",
    "            \n",
    "        # find the arrgrecated output.\n",
    "        # tìm đầu ra được phân bổ.\n",
    "        y_pred = self.prediction_aggrigation_calculation(y_preds)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestRegression(RandomForest):\n",
    "    \"\"\"Rnadom forest for classification task.\"\"\"\n",
    "    def __init__(self, max_feature, max_depth, n_trees=100, min_sample_split=10):\n",
    "        \"\"\"\n",
    "        :param max_depth: Int - Max depth of each tree.\n",
    "        Độ sâu tối đa của mỗi cây.\n",
    "        \n",
    "        :param n_trees: Int - Number of trees/estimetors.\n",
    "        Số cây\n",
    "        \n",
    "        :param min_sample_split: Int - minimum samples for a node to have before going for split.\n",
    "        minimum samples for a node to have before going for split.\n",
    "        các mẫu tối thiểu để một nút có trước khi chia tách.\n",
    "        \n",
    "        :param min_impurity: Int - Min inpurity a node can have.\n",
    "        \"\"\"\n",
    "        self.prediction_aggrigation_calculation = self._mean_calculation\n",
    "        \n",
    "        # Initializing the trees.\n",
    "        # Khởi tạo cây.\n",
    "        self.trees = []\n",
    "        for _ in range(n_trees):\n",
    "            self.trees.append(RegressionTree(min_samples_split=min_sample_split, max_depth=max_depth))\n",
    "\n",
    "        super().__init__(trees=self.trees, n_trees=n_trees,max_feature=max_feature,\n",
    "                         prediction_aggrigation_calculation=self.prediction_aggrigation_calculation)\n",
    "    \n",
    "    def _mean_calculation(self, y_preds):\n",
    "        \"\"\"\n",
    "        Find mean prediction of all tree prediction for each sampple.\n",
    "        Tìm dự đoán trung bình của tất cả dự đoán cây cho từng mẫu.\n",
    "\n",
    "        :param y_preds: Prediction value from number of estimators trees.\n",
    "        Giá trị dự đoán từ số lượng cây ước tính.\n",
    "        \"\"\"\n",
    "        # create a empty array to store the prediction.\n",
    "        # tạo một mảng trống để lưu dự đoán.\n",
    "        y_pred = np.empty((y_preds.shape[0], 1))\n",
    "        # print(y_pred)\n",
    "        # iterate over all the data samples.\n",
    "        # lặp qua tất cả các mẫu dữ liệu.\n",
    "        for i, sample_predictions in enumerate(y_preds):\n",
    "            # print(sample_predictions)\n",
    "            y_pred[i] = np.mean(sample_predictions)\n",
    "            # print('ok')\n",
    "            # print(y_pred)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_table('../IOT/diabetes.tab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AGE', 'SEX', 'BMI', 'BP', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6'], dtype='object')\n",
      "0      151\n",
      "1       75\n",
      "2      141\n",
      "3      206\n",
      "4      135\n",
      "      ... \n",
      "437    178\n",
      "438    104\n",
      "439    132\n",
      "440    220\n",
      "441     57\n",
      "Name: Y, Length: 442, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(columns=['Y'])\n",
    "y = data['Y']\n",
    "print(X.columns)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1) \n",
    "# print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    BMI    S6    S4      Y\n",
      "0  25.6  78.0  3.00   31.0\n",
      "1  25.4  83.0  3.00   25.0\n",
      "2  26.0  97.0  3.37  198.0\n",
      "3  23.1  60.0  3.00  125.0\n",
      "4  21.3  90.0  3.00   42.0\n",
      "       BP   AGE      S5      Y\n",
      "0   98.00  35.0  4.2047  200.0\n",
      "1  103.00  51.0  4.8978  292.0\n",
      "2   83.00  55.0  4.5218   53.0\n",
      "3   82.00  50.0  4.0775  136.0\n",
      "4  123.33  41.0  4.3175  257.0\n",
      "       S5     S1   AGE      Y\n",
      "0  4.8122  186.0  79.0  168.0\n",
      "1  5.3083  186.0  64.0  150.0\n",
      "2  3.8501  155.0  28.0  116.0\n",
      "3  4.5850  171.0  46.0  167.0\n",
      "4  4.2485  255.0  66.0   63.0\n",
      "      S6    S3     S2      Y\n",
      "0  109.0  48.0  112.4  274.0\n",
      "1   88.0  56.0   90.6  121.0\n",
      "2   86.0  42.0   96.8  225.0\n",
      "3   82.0  93.0  108.8   87.0\n",
      "4  103.0  38.0  151.6  192.0\n",
      "      S1     S6    S4      Y\n",
      "0  210.0  124.0  6.00  245.0\n",
      "1  189.0   91.0  3.05   72.0\n",
      "2  157.0   96.0  6.00  144.0\n",
      "3  182.0   84.0  3.00  216.0\n",
      "4  183.0   92.0  2.00   45.0\n",
      "      S1    S4      BP      Y\n",
      "0  209.0  5.00   98.00   83.0\n",
      "1  238.0  4.96  110.67  190.0\n",
      "2  185.0  5.00   93.00  245.0\n",
      "3  189.0  3.00   91.00   90.0\n",
      "4  166.0  3.00   75.00   42.0\n",
      "      BP     S6     S2      Y\n",
      "0   94.0   76.0  104.4   95.0\n",
      "1   96.0  105.0  133.0  177.0\n",
      "2  123.0   97.0  163.6  252.0\n",
      "3   94.0   93.0   74.8  161.0\n",
      "4   93.0   92.0  174.2  122.0\n",
      "    S4      S5     S1      Y\n",
      "0  3.0  4.3820  206.0   59.0\n",
      "1  4.0  4.3944  190.0  214.0\n",
      "2  2.0  4.4188  152.0   77.0\n",
      "3  4.0  4.6540  156.0  162.0\n",
      "4  5.0  4.7005  181.0   91.0\n",
      "   SEX    S3     S2      Y\n",
      "0  2.0  39.0  120.0   91.0\n",
      "1  2.0  29.0  104.8   77.0\n",
      "2  1.0  50.0   85.4   99.0\n",
      "3  1.0  64.0  104.2   72.0\n",
      "4  2.0  39.0  116.2  131.0\n",
      "     S4      BP     S6      Y\n",
      "0  4.00  106.00   96.0  237.0\n",
      "1  2.00   98.00   92.0   45.0\n",
      "2  5.00   98.00   84.0  198.0\n",
      "3  3.65   89.67  101.0   74.0\n",
      "4  2.71   65.33   60.0   65.0\n"
     ]
    }
   ],
   "source": [
    "random_forest_reg = RandomForestRegression(n_trees=10, max_feature=3, min_sample_split=10, max_depth=15)\n",
    "# Train the model.\n",
    "random_forest_reg.train(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      BMI   S6    S4\n",
      "246  23.4   77  3.80\n",
      "425  22.6   79  2.00\n",
      "293  35.0   91  4.08\n",
      "31   20.3   81  2.00\n",
      "359  26.9  106  5.00\n",
      "..    ...  ...   ...\n",
      "277  20.9   95  2.00\n",
      "132  24.4   97  4.00\n",
      "213  19.8   93  3.00\n",
      "286  21.3   90  2.00\n",
      "256  41.3   94  5.00\n",
      "\n",
      "[89 rows x 3 columns]\n",
      "         BP  AGE      S5\n",
      "246   76.67   60  5.1358\n",
      "425   71.00   27  4.4188\n",
      "293   98.33   29  4.0431\n",
      "31    71.00   42  4.2341\n",
      "359  104.00   59  4.8040\n",
      "..      ...  ...     ...\n",
      "277   95.00   39  4.4067\n",
      "132   92.00   53  4.4998\n",
      "213   88.00   49  4.3944\n",
      "286   72.00   38  4.4308\n",
      "256   81.00   35  4.9488\n",
      "\n",
      "[89 rows x 3 columns]\n",
      "         S5   S1  AGE\n",
      "246  5.1358  247   60\n",
      "425  4.4188  116   27\n",
      "293  4.0431  204   29\n",
      "31   4.2341  161   42\n",
      "359  4.8040  194   59\n",
      "..      ...  ...  ...\n",
      "277  4.4067  150   39\n",
      "132  4.4998  214   53\n",
      "213  4.3944  188   49\n",
      "286  4.4308  165   38\n",
      "256  4.9488  168   35\n",
      "\n",
      "[89 rows x 3 columns]\n",
      "      S6    S3     S2\n",
      "246   77  65.0  148.0\n",
      "425   79  56.0   43.4\n",
      "293   91  50.0  142.6\n",
      "31    81  66.0   81.2\n",
      "359  106  43.0  126.6\n",
      "..   ...   ...    ...\n",
      "277   95  68.0   65.6\n",
      "132   97  50.0  146.0\n",
      "213   93  57.0  114.8\n",
      "286   90  88.0   60.2\n",
      "256   94  37.0  102.8\n",
      "\n",
      "[89 rows x 3 columns]\n",
      "      S1   S6    S4\n",
      "246  247   77  3.80\n",
      "425  116   79  2.00\n",
      "293  204   91  4.08\n",
      "31   161   81  2.00\n",
      "359  194  106  5.00\n",
      "..   ...  ...   ...\n",
      "277  150   95  2.00\n",
      "132  214   97  4.00\n",
      "213  188   93  3.00\n",
      "286  165   90  2.00\n",
      "256  168   94  5.00\n",
      "\n",
      "[89 rows x 3 columns]\n",
      "      S1    S4      BP\n",
      "246  247  3.80   76.67\n",
      "425  116  2.00   71.00\n",
      "293  204  4.08   98.33\n",
      "31   161  2.00   71.00\n",
      "359  194  5.00  104.00\n",
      "..   ...   ...     ...\n",
      "277  150  2.00   95.00\n",
      "132  214  4.00   92.00\n",
      "213  188  3.00   88.00\n",
      "286  165  2.00   72.00\n",
      "256  168  5.00   81.00\n",
      "\n",
      "[89 rows x 3 columns]\n",
      "         BP   S6     S2\n",
      "246   76.67   77  148.0\n",
      "425   71.00   79   43.4\n",
      "293   98.33   91  142.6\n",
      "31    71.00   81   81.2\n",
      "359  104.00  106  126.6\n",
      "..      ...  ...    ...\n",
      "277   95.00   95   65.6\n",
      "132   92.00   97  146.0\n",
      "213   88.00   93  114.8\n",
      "286   72.00   90   60.2\n",
      "256   81.00   94  102.8\n",
      "\n",
      "[89 rows x 3 columns]\n",
      "       S4      S5   S1\n",
      "246  3.80  5.1358  247\n",
      "425  2.00  4.4188  116\n",
      "293  4.08  4.0431  204\n",
      "31   2.00  4.2341  161\n",
      "359  5.00  4.8040  194\n",
      "..    ...     ...  ...\n",
      "277  2.00  4.4067  150\n",
      "132  4.00  4.4998  214\n",
      "213  3.00  4.3944  188\n",
      "286  2.00  4.4308  165\n",
      "256  5.00  4.9488  168\n",
      "\n",
      "[89 rows x 3 columns]\n",
      "     SEX    S3     S2\n",
      "246    1  65.0  148.0\n",
      "425    1  56.0   43.4\n",
      "293    1  50.0  142.6\n",
      "31     1  66.0   81.2\n",
      "359    2  43.0  126.6\n",
      "..   ...   ...    ...\n",
      "277    1  68.0   65.6\n",
      "132    2  50.0  146.0\n",
      "213    1  57.0  114.8\n",
      "286    1  88.0   60.2\n",
      "256    1  37.0  102.8\n",
      "\n",
      "[89 rows x 3 columns]\n",
      "       S4      BP   S6\n",
      "246  3.80   76.67   77\n",
      "425  2.00   71.00   79\n",
      "293  4.08   98.33   91\n",
      "31   2.00   71.00   81\n",
      "359  5.00  104.00  106\n",
      "..    ...     ...  ...\n",
      "277  2.00   95.00   95\n",
      "132  4.00   92.00   97\n",
      "213  3.00   88.00   93\n",
      "286  2.00   72.00   90\n",
      "256  5.00   81.00   94\n",
      "\n",
      "[89 rows x 3 columns]\n",
      "[[150.55      ]\n",
      " [113.27361111]\n",
      " [115.02416667]\n",
      " [ 91.31507937]\n",
      " [135.32416667]\n",
      " [157.89095238]\n",
      " [164.92361111]\n",
      " [ 92.20698413]\n",
      " [186.55555556]\n",
      " [123.5574359 ]\n",
      " [192.07825397]\n",
      " [238.85190476]\n",
      " [149.9724359 ]\n",
      " [ 98.5168254 ]\n",
      " [216.7615873 ]\n",
      " [136.97166667]\n",
      " [205.01920635]\n",
      " [ 99.78611111]\n",
      " [174.21079365]\n",
      " [198.42873016]\n",
      " [157.75333333]\n",
      " [107.64678571]\n",
      " [114.22960317]\n",
      " [121.42460317]\n",
      " [131.57138889]\n",
      " [136.71444444]\n",
      " [ 89.22035714]\n",
      " [ 96.00444444]\n",
      " [146.01468254]\n",
      " [174.52190476]\n",
      " [167.7868254 ]\n",
      " [138.53507937]\n",
      " [173.06968254]\n",
      " [ 89.08150794]\n",
      " [162.04603175]\n",
      " [180.975     ]\n",
      " [151.65777778]\n",
      " [170.53357143]\n",
      " [152.03333333]\n",
      " [171.10198413]\n",
      " [148.88309524]\n",
      " [152.15603175]\n",
      " [141.61178571]\n",
      " [111.60988095]\n",
      " [127.56309524]\n",
      " [193.72746032]\n",
      " [150.1968254 ]\n",
      " [131.40563492]\n",
      " [146.00777778]\n",
      " [200.96277778]\n",
      " [108.48055556]\n",
      " [149.77539683]\n",
      " [107.31695971]\n",
      " [125.20511905]\n",
      " [172.6922619 ]\n",
      " [ 82.30277778]\n",
      " [123.64690476]\n",
      " [115.60611111]\n",
      " [122.20186508]\n",
      " [ 74.91440476]\n",
      " [126.46555556]\n",
      " [177.77587302]\n",
      " [189.65972222]\n",
      " [117.71126984]\n",
      " [250.67769841]\n",
      " [ 83.15496032]\n",
      " [112.97583333]\n",
      " [166.46071429]\n",
      " [209.86111111]\n",
      " [128.43960317]\n",
      " [177.96833333]\n",
      " [130.00611111]\n",
      " [132.92333333]\n",
      " [154.4525    ]\n",
      " [164.37222222]\n",
      " [104.6131746 ]\n",
      " [155.27738095]\n",
      " [ 96.61170635]\n",
      " [247.93944444]\n",
      " [164.74003968]\n",
      " [127.44309524]\n",
      " [138.39706349]\n",
      " [144.56301587]\n",
      " [211.34384921]\n",
      " [ 96.72480159]\n",
      " [133.82777778]\n",
      " [106.9525    ]\n",
      " [104.68301587]\n",
      " [161.06174603]]\n",
      "MSE:  4137.3047580833645\n"
     ]
    }
   ],
   "source": [
    "# Predict the values.\n",
    "y_pred = random_forest_reg.predict(X_test)\n",
    "print(y_pred)\n",
    "#Root mean square error.\n",
    "# score = r2_score(y_test, y_pred)\n",
    "# print(\"The r2_score of the trained model\", score)\n",
    "\n",
    "\n",
    "# result = pd.DataFrame({'Actual':y_test, 'Predict':y_pred})\n",
    "\n",
    "print('MSE: ',mean_squared_error(y_test, y_pred))\n",
    "print('r2: ', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246     78\n",
      "425    152\n",
      "293    200\n",
      "31      59\n",
      "359    311\n",
      "      ... \n",
      "277     64\n",
      "132    107\n",
      "213     49\n",
      "286     60\n",
      "256    346\n",
      "Name: Y, Length: 89, dtype: int64\n",
      "[[150.55      ]\n",
      " [113.27361111]\n",
      " [115.02416667]\n",
      " [ 91.31507937]\n",
      " [135.32416667]\n",
      " [157.89095238]\n",
      " [164.92361111]\n",
      " [ 92.20698413]\n",
      " [186.55555556]\n",
      " [123.5574359 ]\n",
      " [192.07825397]\n",
      " [238.85190476]\n",
      " [149.9724359 ]\n",
      " [ 98.5168254 ]\n",
      " [216.7615873 ]\n",
      " [136.97166667]\n",
      " [205.01920635]\n",
      " [ 99.78611111]\n",
      " [174.21079365]\n",
      " [198.42873016]\n",
      " [157.75333333]\n",
      " [107.64678571]\n",
      " [114.22960317]\n",
      " [121.42460317]\n",
      " [131.57138889]\n",
      " [136.71444444]\n",
      " [ 89.22035714]\n",
      " [ 96.00444444]\n",
      " [146.01468254]\n",
      " [174.52190476]\n",
      " [167.7868254 ]\n",
      " [138.53507937]\n",
      " [173.06968254]\n",
      " [ 89.08150794]\n",
      " [162.04603175]\n",
      " [180.975     ]\n",
      " [151.65777778]\n",
      " [170.53357143]\n",
      " [152.03333333]\n",
      " [171.10198413]\n",
      " [148.88309524]\n",
      " [152.15603175]\n",
      " [141.61178571]\n",
      " [111.60988095]\n",
      " [127.56309524]\n",
      " [193.72746032]\n",
      " [150.1968254 ]\n",
      " [131.40563492]\n",
      " [146.00777778]\n",
      " [200.96277778]\n",
      " [108.48055556]\n",
      " [149.77539683]\n",
      " [107.31695971]\n",
      " [125.20511905]\n",
      " [172.6922619 ]\n",
      " [ 82.30277778]\n",
      " [123.64690476]\n",
      " [115.60611111]\n",
      " [122.20186508]\n",
      " [ 74.91440476]\n",
      " [126.46555556]\n",
      " [177.77587302]\n",
      " [189.65972222]\n",
      " [117.71126984]\n",
      " [250.67769841]\n",
      " [ 83.15496032]\n",
      " [112.97583333]\n",
      " [166.46071429]\n",
      " [209.86111111]\n",
      " [128.43960317]\n",
      " [177.96833333]\n",
      " [130.00611111]\n",
      " [132.92333333]\n",
      " [154.4525    ]\n",
      " [164.37222222]\n",
      " [104.6131746 ]\n",
      " [155.27738095]\n",
      " [ 96.61170635]\n",
      " [247.93944444]\n",
      " [164.74003968]\n",
      " [127.44309524]\n",
      " [138.39706349]\n",
      " [144.56301587]\n",
      " [211.34384921]\n",
      " [ 96.72480159]\n",
      " [133.82777778]\n",
      " [106.9525    ]\n",
      " [104.68301587]\n",
      " [161.06174603]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=15, random_state=0)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = RandomForestRegressor(max_depth=15, random_state=0)\n",
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actual     Predict\n",
      "246      78  131.440000\n",
      "425     152  104.337143\n",
      "293     200  165.410000\n",
      "31       59   73.620882\n",
      "359     311  165.753333\n",
      "..      ...         ...\n",
      "277      64   93.135714\n",
      "132     107   95.575238\n",
      "213      49   86.892610\n",
      "286      60   88.229494\n",
      "256     346  166.060000\n",
      "\n",
      "[89 rows x 2 columns]\n",
      "MSE:  3827.715235726259\n",
      "r2:  0.28171579175052086\n"
     ]
    }
   ],
   "source": [
    "predicted_y = regressor.predict(X_test)\n",
    "result = pd.DataFrame({'Actual':y_test, 'Predict':predicted_y})\n",
    "print(result)\n",
    "print('MSE: ',mean_squared_error(y_test, predicted_y))\n",
    "print('r2: ', r2_score(y_test, predicted_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25034407fed5d681614dac11a1c0537e8cb49e3a8883c071303eea01322943d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mysql.connector as mysql\n",
    "from mysql.connector import Error\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## DATABASE CONNECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect():\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = mysql.connect(host='localhost',database='air_quality',user='root',password='password')\n",
    "        if conn.is_connected:\n",
    "            return conn\n",
    "    except Error as e:\n",
    "        print('Error',e)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tamdd18/anaconda3/lib/python3.9/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql_query('SELECT * FROM air_quality.air_quality_raw;',connect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(29531, 17)"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPROCESSING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_full_corr(dataset): # In ra ma trận hệ số corr với tất cả các hàng cột của data (>< 1m10s)\n",
    "#     # remove object type\n",
    "#     drop_col = []\n",
    "#     for i in dataset.columns:\n",
    "#         if dataset[i].dtypes == object:\n",
    "#             drop_col.append(i)\n",
    "#     dataset = dataset.drop(columns = drop_col)\n",
    "#\n",
    "#     list_cov_x_y = []\n",
    "#     len_col = len(dataset.columns)\n",
    "#     len_row = len(dataset)\n",
    "#     labels = list(dataset.columns)\n",
    "#     print(labels)\n",
    "#     #COV(x, y)\n",
    "#     for i in range(0,len_col):\n",
    "#         cov_feat = []\n",
    "#         i_mean = dataset.iloc[:,i].mean()\n",
    "#         for k in range(0, len_col):\n",
    "#             cov_x_y = 0.0\n",
    "#             k_mean = dataset.iloc[:,k].mean()\n",
    "#             for j in range(0,len_row):\n",
    "#                 cov_x_y += (dataset.iloc[j,i]-i_mean)*(dataset.iloc[j,k]-k_mean)\n",
    "#             cov_x_y /= len_row\n",
    "#             cov_feat.append(cov_x_y)\n",
    "#         list_cov_x_y.append(cov_feat)\n",
    "#     print(len(list_cov_x_y))\n",
    "#     #COV(x)\n",
    "#     list_cov_x = []\n",
    "#     for i in range(0,len_col):\n",
    "#         i_mean = dataset.iloc[:,i].mean()\n",
    "#         cov_x = 0.0\n",
    "#         for j in range(0,len_row):\n",
    "#             cov_x += (dataset.iloc[j,i]-i_mean)**2\n",
    "#         cov_x /= (len_row-1)\n",
    "#         list_cov_x.append(cov_x**0.5)\n",
    "#     #COV(y)\n",
    "#     list_cov_y = []\n",
    "#     for i in range(0,len_col):\n",
    "#         cov_y_feat = []\n",
    "#         for k in range(0, len_col):\n",
    "#             cov_y = 0.0\n",
    "#             k_mean = dataset.iloc[:,k].mean()\n",
    "#             for j in range(0,len_row):\n",
    "#                 cov_y += (dataset.iloc[j,k]-k_mean)**2\n",
    "#             cov_y /= (len_row-1)\n",
    "#             cov_y_feat.append(cov_y**0.5)\n",
    "#         list_cov_y.append(cov_y_feat)\n",
    "#     #CORR(x,y)\n",
    "#     list_corr = []\n",
    "#     for i in range(0,len_col):\n",
    "#         tmp_list = []\n",
    "#         for j in range(0, len_col):\n",
    "#             tmp_list.append(list_cov_x_y[i][j]/(list_cov_x[i]*list_cov_y[i][j]))\n",
    "#         list_corr.append(tmp_list)\n",
    "#     #CREATE CORR DATAFRAME\n",
    "#     list_corr = pd.DataFrame(list_corr, columns=labels)\n",
    "#     labels = pd.Index(labels)\n",
    "#     list_corr = list_corr.set_index(labels)\n",
    "#     return list_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_matrix = get_full_corr(df.dropna().drop(columns=['id']))\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.title('Correlation Heatmap of Dataset')\n",
    "# a = sns.heatmap(corr_matrix, square=True, annot=True, fmt='.2f', linecolor='black')\n",
    "# a.set_xticklabels(a.get_xticklabels(), rotation=30)\n",
    "# a.set_yticklabels(a.get_yticklabels(), rotation=30)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   id       City        Date  PM2.5  PM10     NO    NO2    NOx  NH3     CO  \\\n0   1  Ahmedabad  2015-01-01    NaN   NaN   0.92  18.22  17.15  NaN   0.92   \n1   2  Ahmedabad  2015-01-02    NaN   NaN   0.97  15.69  16.46  NaN   0.97   \n2   3  Ahmedabad  2015-01-03    NaN   NaN  17.40  19.30  29.70  NaN  17.40   \n3   4  Ahmedabad  2015-01-04    NaN   NaN   1.70  18.48  17.97  NaN   1.70   \n4   5  Ahmedabad  2015-01-05    NaN   NaN  22.10  21.42  37.76  NaN  22.10   \n\n     SO2      O3  Benzene  Toluene  Xylene  AQI AQI_Bucket  \n0  27.64  133.36     0.00     0.02    0.00  NaN       None  \n1  24.55   34.06     3.68     5.50    3.77  NaN       None  \n2  29.07   30.70     6.80    16.40    2.25  NaN       None  \n3  18.59   36.08     4.43    10.14    1.00  NaN       None  \n4  39.33   39.31     7.01    18.89    2.78  NaN       None  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>City</th>\n      <th>Date</th>\n      <th>PM2.5</th>\n      <th>PM10</th>\n      <th>NO</th>\n      <th>NO2</th>\n      <th>NOx</th>\n      <th>NH3</th>\n      <th>CO</th>\n      <th>SO2</th>\n      <th>O3</th>\n      <th>Benzene</th>\n      <th>Toluene</th>\n      <th>Xylene</th>\n      <th>AQI</th>\n      <th>AQI_Bucket</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Ahmedabad</td>\n      <td>2015-01-01</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.92</td>\n      <td>18.22</td>\n      <td>17.15</td>\n      <td>NaN</td>\n      <td>0.92</td>\n      <td>27.64</td>\n      <td>133.36</td>\n      <td>0.00</td>\n      <td>0.02</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Ahmedabad</td>\n      <td>2015-01-02</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.97</td>\n      <td>15.69</td>\n      <td>16.46</td>\n      <td>NaN</td>\n      <td>0.97</td>\n      <td>24.55</td>\n      <td>34.06</td>\n      <td>3.68</td>\n      <td>5.50</td>\n      <td>3.77</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Ahmedabad</td>\n      <td>2015-01-03</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17.40</td>\n      <td>19.30</td>\n      <td>29.70</td>\n      <td>NaN</td>\n      <td>17.40</td>\n      <td>29.07</td>\n      <td>30.70</td>\n      <td>6.80</td>\n      <td>16.40</td>\n      <td>2.25</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Ahmedabad</td>\n      <td>2015-01-04</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.70</td>\n      <td>18.48</td>\n      <td>17.97</td>\n      <td>NaN</td>\n      <td>1.70</td>\n      <td>18.59</td>\n      <td>36.08</td>\n      <td>4.43</td>\n      <td>10.14</td>\n      <td>1.00</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Ahmedabad</td>\n      <td>2015-01-05</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>22.10</td>\n      <td>21.42</td>\n      <td>37.76</td>\n      <td>NaN</td>\n      <td>22.10</td>\n      <td>39.33</td>\n      <td>39.31</td>\n      <td>7.01</td>\n      <td>18.89</td>\n      <td>2.78</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_corr(df): # In ra ma trận hệ số corr với duy nhất cột nhãn của data (>< 6.6s)\n",
    "#     # remove object type\n",
    "#     drop_col = []\n",
    "#     for i in df.columns:\n",
    "#         if df[i].dtypes == object:\n",
    "#             drop_col.append(i)\n",
    "#     df = df.drop(columns = drop_col)\n",
    "#\n",
    "#     list_cov_x_y = []\n",
    "#     len_col = len(df.columns)\n",
    "#     len_row = len(df)\n",
    "#     labels = list(df.columns)\n",
    "#     print(labels)\n",
    "#     #COV(x, y)\n",
    "#     list_cov_x_y = []\n",
    "#     len_col = len(df.columns)\n",
    "#     len_row = len(df)\n",
    "#     print(len_col, len_row)\n",
    "#     y_mean = df.iloc[:,len_col-1].mean()\n",
    "#     for i in range(0,len_col):\n",
    "#         cov_x_y = 0.0\n",
    "#         x_mean = df.iloc[:,i].mean()\n",
    "#         for j in range(0,len_row):\n",
    "#             cov_x_y += (df.iloc[j,i]-x_mean)*(df.iloc[j,len_col-1]-y_mean)\n",
    "#         cov_x_y /= len_row\n",
    "#         list_cov_x_y.append(cov_x_y)\n",
    "#     #COV(x)\n",
    "#     list_cov_x = []\n",
    "#     for i in range(0,len_col):\n",
    "#         cov_x = 0.0\n",
    "#         x_mean = df.iloc[:,i].mean()\n",
    "#         for j in range(0,len_row):\n",
    "#             cov_x += (df.iloc[j,i]-x_mean)**2\n",
    "#         cov_x /= (len_row-1)\n",
    "#         list_cov_x.append(cov_x**0.5)\n",
    "#     #COV(y)\n",
    "#     list_cov_y = []\n",
    "#     y_mean = df.iloc[:,len_col-1].mean()\n",
    "#     for i in range(0,len_col):\n",
    "#         cov_y = 0.0\n",
    "#         for j in range(0,len_row):\n",
    "#             cov_y += (df.iloc[j,len_col-1]-y_mean)**2\n",
    "#         cov_y /= (len_row-1)\n",
    "#         list_cov_y.append(cov_y**0.5)\n",
    "#     #CORR(x,y)\n",
    "#     list_corr = []\n",
    "#     for i in range(0,len_col):\n",
    "#         list_corr.append(list_cov_x_y[i]/(list_cov_x[i]*list_cov_y[i]))\n",
    "#     #CREATE CORR DATAFRAME\n",
    "#     list_corr = pd.DataFrame(list_corr, columns=['Y'])\n",
    "#     labels = pd.Index(labels)\n",
    "#     list_corr = list_corr.set_index(labels)\n",
    "#     return list_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_matrix = get_corr(df.dropna().drop(columns=['id']))\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.title('Correlation Heatmap of Dataset')\n",
    "# a = sns.heatmap(corr_matrix, square=True, annot=True, fmt='.2f', linecolor='black')\n",
    "# a.set_xticklabels(a.get_xticklabels(), rotation=30)\n",
    "# a.set_yticklabels(a.get_yticklabels(), rotation=30)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   id       City        Date  PM2.5  PM10     NO    NO2    NOx  NH3     CO  \\\n0   1  Ahmedabad  2015-01-01    NaN   NaN   0.92  18.22  17.15  NaN   0.92   \n1   2  Ahmedabad  2015-01-02    NaN   NaN   0.97  15.69  16.46  NaN   0.97   \n2   3  Ahmedabad  2015-01-03    NaN   NaN  17.40  19.30  29.70  NaN  17.40   \n3   4  Ahmedabad  2015-01-04    NaN   NaN   1.70  18.48  17.97  NaN   1.70   \n4   5  Ahmedabad  2015-01-05    NaN   NaN  22.10  21.42  37.76  NaN  22.10   \n\n     SO2      O3  Benzene  Toluene  Xylene  AQI AQI_Bucket  \n0  27.64  133.36     0.00     0.02    0.00  NaN       None  \n1  24.55   34.06     3.68     5.50    3.77  NaN       None  \n2  29.07   30.70     6.80    16.40    2.25  NaN       None  \n3  18.59   36.08     4.43    10.14    1.00  NaN       None  \n4  39.33   39.31     7.01    18.89    2.78  NaN       None  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>City</th>\n      <th>Date</th>\n      <th>PM2.5</th>\n      <th>PM10</th>\n      <th>NO</th>\n      <th>NO2</th>\n      <th>NOx</th>\n      <th>NH3</th>\n      <th>CO</th>\n      <th>SO2</th>\n      <th>O3</th>\n      <th>Benzene</th>\n      <th>Toluene</th>\n      <th>Xylene</th>\n      <th>AQI</th>\n      <th>AQI_Bucket</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Ahmedabad</td>\n      <td>2015-01-01</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.92</td>\n      <td>18.22</td>\n      <td>17.15</td>\n      <td>NaN</td>\n      <td>0.92</td>\n      <td>27.64</td>\n      <td>133.36</td>\n      <td>0.00</td>\n      <td>0.02</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Ahmedabad</td>\n      <td>2015-01-02</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.97</td>\n      <td>15.69</td>\n      <td>16.46</td>\n      <td>NaN</td>\n      <td>0.97</td>\n      <td>24.55</td>\n      <td>34.06</td>\n      <td>3.68</td>\n      <td>5.50</td>\n      <td>3.77</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Ahmedabad</td>\n      <td>2015-01-03</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17.40</td>\n      <td>19.30</td>\n      <td>29.70</td>\n      <td>NaN</td>\n      <td>17.40</td>\n      <td>29.07</td>\n      <td>30.70</td>\n      <td>6.80</td>\n      <td>16.40</td>\n      <td>2.25</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Ahmedabad</td>\n      <td>2015-01-04</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.70</td>\n      <td>18.48</td>\n      <td>17.97</td>\n      <td>NaN</td>\n      <td>1.70</td>\n      <td>18.59</td>\n      <td>36.08</td>\n      <td>4.43</td>\n      <td>10.14</td>\n      <td>1.00</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Ahmedabad</td>\n      <td>2015-01-05</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>22.10</td>\n      <td>21.42</td>\n      <td>37.76</td>\n      <td>NaN</td>\n      <td>22.10</td>\n      <td>39.33</td>\n      <td>39.31</td>\n      <td>7.01</td>\n      <td>18.89</td>\n      <td>2.78</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(columns=['id','SO2','Benzene','Xylene','AQI_Bucket']).dropna()\n",
    "df = df.drop(columns=['id','SO2','Benzene','Xylene','AQI_Bucket','City','Date']).dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New table was created\n"
     ]
    }
   ],
   "source": [
    "# Tạo database cho dữ liệu sau khi xử lý\n",
    "try:\n",
    "    connection = mysql.connect(host='localhost', database='air_quality', user='root', password='password')\n",
    "    if connection.is_connected():\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\n",
    "            'CREATE TABLE if not exists preprocessed_air_quality (ID int NOT NULL AUTO_INCREMENT PRIMARY KEY,`PM2.5` double,`PM10` double,`NO` double,`NO2` double,NOx double,`NH3` double,`CO` double,O3 double,Toluene double,AQI double)')\n",
    "        print('New table was created')\n",
    "        connection.commit()\n",
    "        cursor.close()\n",
    "except Error as e:\n",
    "    print('Error', e)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\ntry:\\n    connection = mysql.connect(host=\\'localhost\\', database=\\'air_quality\\', user=\\'root\\', password=\\'cuong#Super2001\\')\\n    if connection.is_connected():\\n        cursor = connection.cursor()\\n        for i, row in df.iterrows():\\n            sql = \"INSERT INTO preprocessed_air_quality(`PM2.5`,`PM10`,`NO`,`NO2`,NOx,`NH3`,`CO`,O3,Toluene,AQI) VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\"\\n            cursor.execute(sql, tuple(row))\\n            # print(\\'Inserted record\\')\\n        connection.commit()\\n        cursor.close()\\nexcept Error as e:\\n    print(\\'Error\\', e)\\n\\n'"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import records of corr_matrix into database\n",
    "'''\n",
    "try:\n",
    "    connection = mysql.connect(host='localhost', database='air_quality', user='root', password='cuong#Super2001')\n",
    "    if connection.is_connected():\n",
    "        cursor = connection.cursor()\n",
    "        for i, row in df.iterrows():\n",
    "            sql = \"INSERT INTO preprocessed_air_quality(`PM2.5`,`PM10`,`NO`,`NO2`,NOx,`NH3`,`CO`,O3,Toluene,AQI) VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\"\n",
    "            cursor.execute(sql, tuple(row))\n",
    "            # print('Inserted record')\n",
    "        connection.commit()\n",
    "        cursor.close()\n",
    "except Error as e:\n",
    "    print('Error', e)\n",
    "\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(features, label_name, test_size, random_state):\n",
    "    shuffle_feature_df = features.sample(frac = 1,random_state=random_state)\n",
    "    test_size = int(test_size*len(features))\n",
    "    X_train = shuffle_feature_df[test_size:]\n",
    "    X_test = shuffle_feature_df[:test_size]\n",
    "    y_train = X_train[label_name]\n",
    "    y_test = X_test[label_name]\n",
    "    X_train = X_train.drop(columns=[label_name])\n",
    "    X_test = X_test.drop(columns=[label_name])\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df,'AQI',test_size=0.3,random_state=1)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(df1,'AQI',test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7672, 9)   (3288, 9)   (10960, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,' ',X_test.shape,' ',df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "       PM2.5    PM10     NO    NO2    NOx    NH3    CO      O3  Toluene\n10857  94.23  141.30  38.60  86.20  94.51  28.66  1.30  134.72     5.13\n15770  35.90   79.03   7.78  50.76  32.78  22.05  0.76   49.00     5.57\n16459  42.14  107.78  10.13  28.15  21.56  20.99  0.46   31.40     4.73\n11565  36.06   65.58  15.31  26.12  27.86  29.36  0.90   21.53    28.23\n16132  39.01  104.02   4.71  32.84  21.16  14.24  0.58   34.99     9.57",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PM2.5</th>\n      <th>PM10</th>\n      <th>NO</th>\n      <th>NO2</th>\n      <th>NOx</th>\n      <th>NH3</th>\n      <th>CO</th>\n      <th>O3</th>\n      <th>Toluene</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10857</th>\n      <td>94.23</td>\n      <td>141.30</td>\n      <td>38.60</td>\n      <td>86.20</td>\n      <td>94.51</td>\n      <td>28.66</td>\n      <td>1.30</td>\n      <td>134.72</td>\n      <td>5.13</td>\n    </tr>\n    <tr>\n      <th>15770</th>\n      <td>35.90</td>\n      <td>79.03</td>\n      <td>7.78</td>\n      <td>50.76</td>\n      <td>32.78</td>\n      <td>22.05</td>\n      <td>0.76</td>\n      <td>49.00</td>\n      <td>5.57</td>\n    </tr>\n    <tr>\n      <th>16459</th>\n      <td>42.14</td>\n      <td>107.78</td>\n      <td>10.13</td>\n      <td>28.15</td>\n      <td>21.56</td>\n      <td>20.99</td>\n      <td>0.46</td>\n      <td>31.40</td>\n      <td>4.73</td>\n    </tr>\n    <tr>\n      <th>11565</th>\n      <td>36.06</td>\n      <td>65.58</td>\n      <td>15.31</td>\n      <td>26.12</td>\n      <td>27.86</td>\n      <td>29.36</td>\n      <td>0.90</td>\n      <td>21.53</td>\n      <td>28.23</td>\n    </tr>\n    <tr>\n      <th>16132</th>\n      <td>39.01</td>\n      <td>104.02</td>\n      <td>4.71</td>\n      <td>32.84</td>\n      <td>21.16</td>\n      <td>14.24</td>\n      <td>0.58</td>\n      <td>34.99</td>\n      <td>9.57</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score_1(y_test, y_pred):\n",
    "    y_test = y_test.to_numpy()\n",
    "    # y_pred = y_pred.reshape(-1)\n",
    "    y_test_avg = np.mean(y_test)\n",
    "    result = 0\n",
    "    n = len(y_test)\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for i in range(n):\n",
    "        numerator += math.pow((y_test[i] - y_pred[i]), 2)\n",
    "        denominator += math.pow((y_test[i] - y_test_avg), 2)\n",
    "    result = 1 - (numerator / denominator)\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error_1(y_test, y_pred):\n",
    "    y_test = y_test.to_numpy()\n",
    "    # y_pred = y_pred.reshape(-1)\n",
    "    result = 0\n",
    "    n = len(y_test)\n",
    "    for i in range(n):\n",
    "        result += math.pow((y_test[i] - y_pred[i]), 2)\n",
    "    result /= n\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MACHINE LEARNING MODELS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Node:\n",
    "#\n",
    "#     def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "#         self.feature = feature\n",
    "#         self.threshold = threshold\n",
    "#         self.left = left\n",
    "#         self.right = right\n",
    "#         self.value = value\n",
    "#\n",
    "#     def is_leaf_node(self):\n",
    "#         return self.value is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Decision Tree Regressor Class\n",
    "# class RegressionTree:\n",
    "#     def __init__(self,max_depth = 15,min_samples_split = 10):\n",
    "#         self.root = None\n",
    "#         self.max_depth = max_depth\n",
    "#         self.min_samples_split = min_samples_split\n",
    "#\n",
    "#     def fit(self, X, Y):\n",
    "#         self.n_feats = X.shape[1]\n",
    "#         self.col = list(X.columns)\n",
    "#         self.root = self.growTree(X, Y)\n",
    "#\n",
    "#     def growTree(self, X, Y, depth = 0):\n",
    "#         df = X.copy()\n",
    "#         df['y'] = Y\n",
    "#         ymean = np.mean(Y)\n",
    "#         self.mse = self.get_mse(Y, ymean)\n",
    "#         n_sample = X.shape[0]\n",
    "#         # stopping criteria\n",
    "#         if depth >= self.max_depth or n_sample <= self.min_samples_split:\n",
    "#             leaf_value = np.mean(Y)\n",
    "#             return Node(value=leaf_value)\n",
    "#         best_feat, best_thresh = self.best_criteria(X, Y)\n",
    "#         left_df, right_df = df[df[best_feat]<=best_thresh].copy(), df[df[best_feat]>best_thresh].copy()\n",
    "#         left = self.growTree(left_df.drop('y', axis=1), left_df['y'].values.tolist(), depth+1)\n",
    "#         right = self.growTree(right_df.drop('y', axis=1), right_df['y'].values.tolist(), depth+1)\n",
    "#         return Node(best_feat, best_thresh, left, right)\n",
    "#\n",
    "#     # find out best criteria\n",
    "#     def best_criteria(self, X, Y):\n",
    "#         df = X.copy()\n",
    "#         df['y'] = Y\n",
    "#         mse_base = self.mse\n",
    "#         best_feature = best_thresh = None\n",
    "#         for feat in X.columns:\n",
    "#             x_mean = self.moving_average(np.unique(df[feat]), 2)\n",
    "#             for value in x_mean:\n",
    "#                 left_y = df[df[feat] <= value]['y'].values\n",
    "#                 right_y = df[df[feat] > value]['y'].values\n",
    "#                 left_mean = right_mean = 0\n",
    "#                 if len(left_y) > 0:\n",
    "#                     left_mean = np.mean(left_y)\n",
    "#                 if len(right_y) > 0:\n",
    "#                     right_mean = np.mean(right_y)\n",
    "#\n",
    "#                 res_left, res_right = left_y - left_mean, right_y - right_mean\n",
    "#                 r = np.concatenate((res_left, res_right), axis=None)\n",
    "#                 n = len(r)\n",
    "#                 r = np.sum(r**2)\n",
    "#                 mse_split = r / n\n",
    "#                 if mse_split < mse_base:\n",
    "#                     mse_base = mse_split\n",
    "#                     best_feature = feat\n",
    "#                     best_thresh = value\n",
    "#         return (best_feature, best_thresh)\n",
    "#\n",
    "#     def get_mse(self, y_true, y_hat):\n",
    "#         n = len(y_true)\n",
    "#         r = np.sum((y_true - y_hat)**2)\n",
    "#         return r / n\n",
    "#\n",
    "#     def moving_average(self, x, window):\n",
    "#         return np.convolve(x, np.ones(window), 'valid') / window\n",
    "#\n",
    "#     def predict(self, X):\n",
    "#         X = X.to_numpy().tolist()\n",
    "#         return np.array([self.traverse_tree(x, self.root) for x in X])\n",
    "#\n",
    "#     def traverse_tree(self, x, node):\n",
    "#         if node.value is not None:\n",
    "#             return node.value\n",
    "#         fr = node.feature\n",
    "#         index = self.col.index(fr)\n",
    "#         if x[index] <= node.threshold:\n",
    "#             return self.traverse_tree(x, node.left)\n",
    "#         return self.traverse_tree(x, node.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression_tree = RegressionTree(min_samples_split=100, max_depth=5) #2m46.5s\n",
    "# regression_tree.fit(X_train, y_train)\n",
    "# y_pred_tree = regression_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('MSE: ',mean_squared_error_1(y_test, y_pred_tree))\n",
    "# print('r2: ', r2_score_1(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RandomForest:\n",
    "#     def __init__(self, trees, n_trees, max_feature, prediction_aggrigation_calculation):\n",
    "#         self.n_estimators = n_trees\n",
    "#         self.max_features = max_feature\n",
    "#         self.tree_feature_indexes = []\n",
    "#         self.prediction_aggrigation_calculation = prediction_aggrigation_calculation\n",
    "#         self.trees = trees\n",
    "#\n",
    "#     def _make_random_suset(self, X, y, n_subsets, replasment=True):\n",
    "#         subset = []\n",
    "#         sample_size = (X.shape[0] if replasment else (X.shape[0] // 2))\n",
    "#\n",
    "#         X = X.to_numpy()\n",
    "#         y = y.to_numpy()\n",
    "#         y = np.reshape(y, (len(y),1))\n",
    "#         Xy = np.concatenate((X, y), axis=1)\n",
    "#\n",
    "#         np.random.shuffle(Xy)\n",
    "#         for i in range(n_subsets):\n",
    "#             index = np.random.choice(range(sample_size), size=np.shape(range(sample_size)), replace=replasment)\n",
    "#             X = Xy[index][:, :-1]\n",
    "#             y = Xy[index][: , -1]\n",
    "#             subset.append({\"X\" : X, \"y\": y})\n",
    "#         return subset\n",
    "#\n",
    "#     def train(self, X, y):\n",
    "#         n_features = X.shape[1]\n",
    "#         name_columns = list(X.columns)\n",
    "#\n",
    "#         if self.max_features == None:\n",
    "#             self.max_features = int(math.sqrt(n_features))\n",
    "#\n",
    "#         subsets = self._make_random_suset(X, y, self.n_estimators)\n",
    "#\n",
    "#         for i, subset in enumerate(subsets):\n",
    "#             X_subset , y_subset = subset[\"X\"], subset[\"y\"]\n",
    "#             idx = np.random.choice(range(n_features), size=self.max_features, replace=False)\n",
    "#\n",
    "#             self.tree_feature_indexes.append(idx)\n",
    "#             X_subset = X_subset[:, idx]\n",
    "#             selected_name_columns = []\n",
    "#             # print(idx)\n",
    "#             for j in range(len(idx)):\n",
    "#                 selected_name_columns.append(name_columns[idx[j]])\n",
    "#             selected_name_columns.append('Y')\n",
    "#             y_subset = np.expand_dims(y_subset, axis =1)\n",
    "#             Xy_subset = np.concatenate((X_subset, y_subset), axis=1)\n",
    "#             Xy_subset = pd.DataFrame(Xy_subset, columns=selected_name_columns)\n",
    "#             print(Xy_subset.head())\n",
    "#             X_set = Xy_subset.drop(columns=['Y'])\n",
    "#             y_set = Xy_subset['Y']\n",
    "#             self.trees[i].fit(X_set, y_set)\n",
    "#\n",
    "#     def predict(self, test_X):\n",
    "#         y_preds = np.empty((test_X.shape[0], self.n_estimators))\n",
    "#         for i, tree in enumerate(self.trees):\n",
    "#             features_index = self.tree_feature_indexes[i]\n",
    "#             col_name = list(test_X.columns)\n",
    "#             selected_col_name = []\n",
    "#             for j in features_index:\n",
    "#                 selected_col_name.append(col_name[j])\n",
    "#             X_selected_features = test_X[selected_col_name]\n",
    "#             print(X_selected_features)\n",
    "#             y_preds[:, i] = tree.predict(X_selected_features)\n",
    "#         y_pred = self.prediction_aggrigation_calculation(y_preds)\n",
    "#\n",
    "#         return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RandomForestRegression(RandomForest):\n",
    "#     def __init__(self, max_feature, max_depth, n_trees=100, min_sample_split=10):\n",
    "#         self.prediction_aggrigation_calculation = self._mean_calculation\n",
    "#         self.trees = []\n",
    "#         for _ in range(n_trees):\n",
    "#             self.trees.append(RegressionTree(min_samples_split=min_sample_split, max_depth=max_depth))\n",
    "#\n",
    "#         super().__init__(trees=self.trees, n_trees=n_trees,max_feature=max_feature,\n",
    "#                          prediction_aggrigation_calculation=self.prediction_aggrigation_calculation)\n",
    "#\n",
    "#     def _mean_calculation(self, y_preds):\n",
    "#         y_pred = np.empty((y_preds.shape[0], 1))\n",
    "#         for i, sample_predictions in enumerate(y_preds):\n",
    "#             y_pred[i] = np.mean(sample_predictions)\n",
    "#\n",
    "#         return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_forest_reg = RandomForestRegression(n_trees=1, max_feature=3, min_sample_split=10, max_depth=15)\n",
    "# random_forest_reg.train(X_train, y_train)\n",
    "# y_pred_forest = random_forest_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('MSE: ',mean_squared_error(y_test, y_pred_forest))\n",
    "# print('r2: ', r2_score(y_test, y_pred_forest))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression:\n",
    "    def __init__(self, learning_rate, iteration, regularization):\n",
    "        \"\"\"\n",
    "        :param learning_rate: A samll value needed for gradient decent, default value id 0.1.\n",
    "        :param iteration: Number of training iteration, default value is 10,000.\n",
    "        \"\"\"\n",
    "        self.m = None\n",
    "        self.n = None\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.regularization = regularization  # will be the l1/l2 regularization class according to the regression model.\n",
    "        self.lr = learning_rate\n",
    "        self.it = iteration\n",
    "\n",
    "    def cost_function(self, y, y_pred):\n",
    "        \"\"\"\n",
    "        :param y: Original target value.\n",
    "        :param y_pred: predicted target value.\n",
    "        \"\"\"\n",
    "        return (1 / (2 * self.m)) * np.sum(np.square(y_pred - y)) + self.regularization(self.w)\n",
    "\n",
    "    def hypothesis(self, weights, bias, X):\n",
    "        \"\"\"\n",
    "        :param weights: parameter value weight.\n",
    "        :param X: Training samples.\n",
    "        \"\"\"\n",
    "        return np.dot(X, weights)  #+ bias\n",
    "\n",
    "    def train(self, X, y):\n",
    "        X = np.insert(X, 0, 1, axis=1)\n",
    "\n",
    "        try:\n",
    "            y.shape[1]\n",
    "        except IndexError as e:\n",
    "            print(\"y phải có shape (n,1)-1 D array, không phải (n,)-list\")\n",
    "            return\n",
    "\n",
    "        self.m = X.shape[0]\n",
    "        self.n = X.shape[1]\n",
    "\n",
    "        self.w = np.zeros((self.n, 1))\n",
    "\n",
    "        self.b = 0\n",
    "\n",
    "        for it in range(1, self.it + 1):\n",
    "            y_pred = self.hypothesis(self.w, self.b, X)\n",
    "            cost = self.cost_function(y, y_pred)\n",
    "            dw = (1 / self.m) * np.dot(X.T, (y_pred - y)) + self.regularization.derivation(self.w)\n",
    "\n",
    "            self.w = self.w - self.lr * dw\n",
    "\n",
    "            if it % 10 == 0:\n",
    "                print(\"The Cost function for the iteration {}----->{} :)\".format(it, cost))\n",
    "\n",
    "    def predict(self, test_X):\n",
    "        test_X = np.insert(test_X, 0, 1, axis=1)\n",
    "\n",
    "        y_pred = self.hypothesis(self.w, self.b, test_X)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class l1_regularization:\n",
    "\n",
    "    def __init__(self, lamda):\n",
    "        self.lamda = lamda\n",
    "\n",
    "    def __call__(self, weights):\n",
    "        return self.lamda * np.sum(np.abs(weights))\n",
    "\n",
    "    def derivation(self, weights):\n",
    "        return self.lamda * np.sign(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LassoRegression(Regression):\n",
    "\n",
    "    def __init__(self, lamda, learning_rate, iteration):\n",
    "        self.regularization = l1_regularization(lamda)\n",
    "        super(LassoRegression, self).__init__(learning_rate, iteration, self.regularization)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        return super(LassoRegression, self).train(X, y)\n",
    "\n",
    "    def predict(self, test_X):\n",
    "        return super(LassoRegression, self).predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "The Cost function for the iteration 10----->0    2321.913696\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 20----->0    1552.081275\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 30----->0    1200.237128\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 40----->0    1028.353923\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 50----->0    935.265788\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 60----->0    877.812952\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 70----->0    837.441914\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 80----->0    806.055608\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 90----->0    780.016221\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 100----->0    757.601192\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 110----->0    737.922169\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 120----->0    720.464048\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 130----->0    704.887062\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 140----->0    690.940664\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 150----->0    678.425078\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 160----->0    667.173324\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 170----->0    657.042142\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 180----->0    647.9656\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 190----->0    639.81756\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 200----->0    632.457778\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 210----->0    625.802295\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 220----->0    619.778122\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 230----->0    614.325756\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 240----->0    609.371919\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 250----->0    604.86595\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 260----->0    600.777411\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 270----->0    597.036285\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 280----->0    593.63859\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 290----->0    590.52161\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 300----->0    587.675358\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 310----->0    585.071751\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 320----->0    582.673674\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 330----->0    580.472095\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 340----->0    578.453815\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 350----->0    576.593271\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 360----->0    574.870395\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 370----->0    573.278578\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 380----->0    571.805716\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 390----->0    570.440984\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 400----->0    569.174503\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 410----->0    567.997602\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 420----->0    566.902416\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 430----->0    565.881791\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 440----->0    564.929262\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 450----->0    564.039074\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 460----->0    563.205533\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 470----->0    562.418543\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 480----->0    561.678771\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 490----->0    560.989179\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 500----->0    560.341648\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 510----->0    559.73126\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 520----->0    559.18529\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 530----->0    558.690907\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 540----->0    558.223408\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 550----->0    557.765295\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 560----->0    557.341321\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 570----->0    556.941605\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 580----->0    556.546501\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 590----->0    556.179903\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 600----->0    555.821856\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 610----->0    555.481845\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 620----->0    555.157187\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 630----->0    554.842884\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 640----->0    554.5432\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 650----->0    554.257762\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 660----->0    553.976993\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 670----->0    553.717247\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 680----->0    553.453719\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 690----->0    553.214903\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 700----->0    552.969491\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 710----->0    552.748272\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 720----->0    552.522786\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 730----->0    552.310589\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 740----->0    552.110795\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 750----->0    551.906962\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 760----->0    551.721648\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 770----->0    551.530743\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 780----->0    551.356512\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 790----->0    551.18503\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 800----->0    551.015704\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 810----->0    550.854329\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 820----->0    550.69768\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 830----->0    550.548692\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 840----->0    550.397216\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 850----->0    550.261002\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 860----->0    550.117872\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 870----->0    549.985624\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 880----->0    549.862306\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 890----->0    549.724518\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 900----->0    549.61245\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 910----->0    549.493307\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 920----->0    549.36996\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 930----->0    549.269878\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 940----->0    549.155963\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 950----->0    549.049058\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 960----->0    548.949064\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 970----->0    548.847852\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 980----->0    548.755221\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 990----->0    548.653579\n",
      "dtype: float64 :)\n",
      "The Cost function for the iteration 1000----->0    548.569707\n",
      "dtype: float64 :)\n",
      "MSE:  1393.8144593002653\n",
      "r2:  0.8434790801125603\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "X_train_tmp = X_train.to_numpy()\n",
    "X_test_tmp = X_test.to_numpy()\n",
    "y_train_tmp = pd.DataFrame(y_train.to_numpy().reshape(-1, 1))\n",
    "y_test_tmp = pd.DataFrame(y_test.to_numpy().reshape(-1, 1))\n",
    "\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train_tmp)\n",
    "X_test_minmax = min_max_scaler.fit_transform(X_test_tmp)\n",
    "\n",
    "param = {\n",
    "    \"lamda\": 0.1,\n",
    "    \"learning_rate\": 1,\n",
    "    \"iteration\": 1000\n",
    "}\n",
    "print(\"=\" * 100)\n",
    "linear_reg = LassoRegression(**param)\n",
    "\n",
    "\n",
    "linear_reg.train(X_train_minmax, y_train_tmp)\n",
    "\n",
    "y_pred = linear_reg.predict(X_test_minmax)\n",
    "\n",
    "print('MSE: ', mean_squared_error(y_test_tmp, y_pred))\n",
    "print('r2: ', r2_score(y_test_tmp, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  836.5679077813354\n",
      "r2:  0.9060560911816185\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso_regression = Lasso(alpha=0.1, max_iter=1000)\n",
    "lasso_regression.fit(X_train, y_train)\n",
    "y_pred_lasso = lasso_regression.predict(X_test)\n",
    "\n",
    "print('MSE: ',mean_squared_error_1(y_test, y_pred_lasso))\n",
    "print('r2: ', r2_score_1(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5791     120.0\n",
      "2738      68.0\n",
      "28180    116.0\n",
      "28096     78.0\n",
      "18946     78.0\n",
      "         ...  \n",
      "10705    291.0\n",
      "10611    424.0\n",
      "10371    321.0\n",
      "5867     112.0\n",
      "9694      74.0\n",
      "Name: AQI, Length: 3288, dtype: float64\n",
      "[[162.34912421]\n",
      " [ 27.3126778 ]\n",
      " [168.47723302]\n",
      " ...\n",
      " [315.11420599]\n",
      " [125.34870198]\n",
      " [102.39718006]]\n",
      "                City        Date  PM2.5    PM10     NO    NO2    NOx    NH3  \\\n",
      "5791       Bengaluru  2019-02-06  60.08  115.27  10.06  38.44  33.98  14.13   \n",
      "2738       Amaravati  2019-08-02   6.85   13.30   1.61   1.52   1.86   2.44   \n",
      "28180  Visakhapatnam  2016-10-20  64.67  112.79  12.26  56.35  37.63  14.86   \n",
      "28096  Visakhapatnam  2016-07-28  21.85   68.36  26.31  31.72  34.93  12.91   \n",
      "18946          Kochi  2020-04-07  14.02   23.28  77.87   2.41  63.90   3.44   \n",
      "\n",
      "         CO     O3  Toluene  Actual AQI  Predicted AQI  \n",
      "5791   0.88  78.02     1.37       120.0     162.349124  \n",
      "2738   0.46  18.07     0.26        68.0      27.312678  \n",
      "28180  1.13  43.97    11.60       116.0     168.477233  \n",
      "28096  0.98  18.39    10.57        78.0     110.963004  \n",
      "18946  0.88   1.29     0.00        78.0      95.803168  \n"
     ]
    },
    {
     "data": {
      "text/plain": "3288"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('mysql+mysqlconnector://root:password@localhost:3306/air_quality', echo=False)\n",
    "x_columns = ['City', 'Date', 'PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'O3', 'Toluene']\n",
    "y_test_column = ['Actual AQI']\n",
    "y_pred_column = ['Predicted AQI']\n",
    "\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "\n",
    "result = pd.DataFrame(X_test1, columns=x_columns)\n",
    "result['Actual AQI'] = y_test\n",
    "result['Predicted AQI'] = y_pred\n",
    "\n",
    "print(result.head())\n",
    "result.to_sql(con=engine, name='air_quality_lasso', if_exists='append', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "\n",
    "    def __init__(self, lr = 0.001, n_iters=1000):\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for i in range(self.n_iters):\n",
    "            y_pred = np.dot(X, self.weights) + self.bias\n",
    "\n",
    "            dw = (1/n_samples) * np.dot(X.T, (y_pred-y))\n",
    "            db = (1/n_samples) * np.sum(y_pred-y)\n",
    "\n",
    "            self.weights = self.weights - self.lr * dw\n",
    "            self.bias = self.bias - self.lr * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = np.dot(X, self.weights) + self.bias\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression = LinearRegression(lr=0.01)\n",
    "linear_regression.fit(X_train, y_train)\n",
    "y_pred = linear_regression.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  nan\n",
      "r2:  nan\n"
     ]
    }
   ],
   "source": [
    "print('MSE: ',mean_squared_error(y_test, y_pred))\n",
    "print('r2: ', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighbors Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        self.x_train = x_train.values\n",
    "        self.y_train = y_train.values\n",
    "    def predict(self, x_test):\n",
    "        self.x_test = x_test.values\n",
    "        y_pred = []\n",
    "        # calculate euclidean distances  \n",
    "        for i in range(len(self.x_test)):  # for every sample in x_test\n",
    "            distance = []\n",
    "            for j in range(len(self.x_train)):  # for every sample in x_train\n",
    "                    # euclidean distance\n",
    "                d = (np.sqrt(np.sum(np.square(self.x_test[i, :] - self.x_train[j, :]))))\n",
    "                distance.append((d, self.y_train[j]))\n",
    "            # sort distances in ascending order\n",
    "            distance = sorted(distance)\n",
    "            # get k-nearest neighbors\n",
    "            neighbors = []\n",
    "            for item in range(self.k):\n",
    "                neighbors.append(distance[item][1])  \n",
    "            y_pred.append(np.mean(neighbors))  \n",
    "            \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNN(k=7)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  661.9502892397848\n",
      "r2:  0.9256650930113159\n"
     ]
    }
   ],
   "source": [
    "print('MSE: ',mean_squared_error_1(y_test, y_pred_knn))\n",
    "print('r2: ', r2_score_1(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKLEARN MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import các mô hình thuật toán sklearn\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = DecisionTreeRegressor(max_depth=5,min_samples_split=100)\n",
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tree_1 = regressor.predict(X_test)\n",
    "print('DECISION TREE REGRESSOR')\n",
    "result = pd.DataFrame({'Actual':y_test, 'Predict 1':y_pred_tree, 'Predict 2':y_pred_tree_1})\n",
    "print('MSE 1: ',mean_squared_error_1(y_test, y_pred_tree),' MSE 2: ',mean_squared_error_1(y_test,y_pred_tree_1))\n",
    "print('r2 1: ', r2_score(y_test, y_pred_tree),' r2 2: ',r2_score(y_test, y_pred_tree_1))\n",
    "result.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "25034407fed5d681614dac11a1c0537e8cb49e3a8883c071303eea01322943d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
